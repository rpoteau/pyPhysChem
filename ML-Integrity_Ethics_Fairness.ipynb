{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10024ca9-7e94-4f5c-a982-b4537b919d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cwd0 = './config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID_Eng as vID\n",
    "vID.init(cwd0)\n",
    "import tools4pyPhysChem as t4pPC\n",
    "\n",
    "#cancel the \"last show-up\" behaviour of Jupyter notebooks\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e4b9b",
   "metadata": {},
   "source": [
    "# Integrity and ethics\n",
    "\n",
    "<figure>\n",
    "<img width = \"700px\" src=\"./ML-Figures/Ethics.png\" alt=\"AI and Ethics\" />\n",
    "<figcaption>Potential conflict between AI, ethics, transparency, data, and the need for scientific rigor in research</figcaption>\n",
    "</figure> \n",
    "\n",
    "## Overview\n",
    "\n",
    "### Questions for chatGPT\n",
    "\n",
    "<div class=\"intro\">\n",
    "    \n",
    "***September 8, 2025, ChatGPT 5.0***\n",
    "    \n",
    "Hi ChatGPT, can you write 5 paragraphs, with approximately 600 characters per paragraph, arguing the importance of ethics in scientific research. This article should illustrate 5 practical cases, using a generative AI such as you :\n",
    "    \n",
    "- analyzing data\n",
    "- producing algorithms as black boxes\n",
    "- refining data\n",
    "- making a decision in medicine\n",
    "- the fifth one is opened: what is your vision of ethics at the age of AI ?\n",
    "\n",
    "And can you first polish my English, this questioning will be pasted in a Jupyter notebook at the occasion of a workshop of AI in nanaoscience\n",
    "<br>\n",
    "\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div class=\"introE\">\n",
    "    \n",
    "**Polished Question**\n",
    "\n",
    "Hi ChatGPT, can you write five paragraphs, each of about 600 characters, arguing for the importance of ethics in scientific research? This article should illustrate five practical cases, using a generative AI such as you:\n",
    "\n",
    "1. Analyzing data\n",
    "2. Producing algorithms as black boxes\n",
    "3. Refining data\n",
    "4. Making decisions in medicine\n",
    "5. An open reflection: what is your vision of ethics in the age of AI?\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"introE\">\n",
    "\n",
    "**1. Analyzing Data.** \n",
    "When researchers use AI to analyze data, ethics demands transparency about sources, processing methods, and possible biases. For example, if nanoscience data are incomplete or unbalanced, an AI may amplify hidden trends, leading to misleading results. Responsible practice requires documenting how datasets are built, applying fairness checks, and ensuring reproducibility. Ethical data analysis not only protects scientific integrity but also preserves the trust of both academic and public communities.\n",
    "\n",
    "**2. Producing Algorithms as Black Boxes.** \n",
    "AI systems often generate models that behave like black boxes, producing predictions without offering clear explanations. While accurate, such opacity undermines accountability in scientific research. An ethical approach calls for explainable AI: researchers should favor models that allow interpretation of results, even if they sacrifice some accuracy. By providing insight into decision-making processes, explainable algorithms protect against misuse, build confidence, and support responsible scientific conclusions.\n",
    "\n",
    "**3. Refining Data.** \n",
    "AI can refine raw data by filtering noise, correcting errors, or generating synthetic datasets. However, ethical risks arise if refinements distort reality or introduce artificial patterns. In nanoscience, refining experimental spectra must avoid over-smoothing, which could hide meaningful features. Ethical responsibility involves setting clear limits on preprocessing, documenting transformations, and ensuring that the refined data reflect scientific truth rather than convenience. Data refinement must serve discovery, not manipulation.\n",
    "\n",
    "**4. Making Decisions in Medicine.** \n",
    "In medicine, AI may help decide treatments, but ethical vigilance is crucial. An algorithm trained on biased clinical data could recommend less effective therapies for underrepresented groups. Moreover, delegating life-critical decisions entirely to a machine removes human accountability. Ethical practice insists on keeping the physician in control, using AI as an assistant rather than a judge. This ensures that human dignity, contextual knowledge, and compassion remain at the heart of medical decisions.\n",
    "\n",
    "**5. Ethics in the Age of AI.** \n",
    "At the age of AI, ethics becomes a compass for navigating rapid technological change. Scientific research must balance innovation with responsibility: protecting privacy, reducing environmental costs of computation, and preventing algorithmic harm. My vision is that ethics should be embedded in every stage of AI design, from dataset collection to deployment. Far from slowing progress, ethical reflection strengthens science by making it trustworthy, inclusive, and aligned with societal values.\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div class=\"intro\">\n",
    "\n",
    "**Privacy & Intellectual Ownership discussion:**\n",
    "\n",
    "1. What happens if a researcher uploads data or a draft article that is still in progress?\n",
    "2. Company Policy: What is OpenAI’s policy on this topic?\n",
    "3. Patents: Can I patent something if I exchanged with ChatGPT during the invention process?\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"introE\">\n",
    "    \n",
    "<u>**Q1. Privacy & Intellectual Ownership.** What happens if a researcher uploads data or a draft article that is still in progress?</u>\n",
    "\n",
    "Uploading unpublished data or a draft article to an AI tool raises two main risks:  \n",
    "\n",
    "- **Confidentiality:** Scientific data may contain sensitive results, collaborations, or even personal information that must not be disclosed without consent.  \n",
    "- **Authorship:** Drafts are intellectual property, and sharing them outside the research team without agreement could compromise ownership and priority.  \n",
    "\n",
    "**Best practice:** Use AI tools for private brainstorming or style polishing, but avoid uploading co-authored or sensitive materials unless all parties agree. Always keep records of what was uploaded and how AI contributed.\n",
    "\n",
    "\n",
    "<u>**Q2. Company Policy (OpenAI):** What is OpenAI’s policy on this topic?</u>\n",
    "\n",
    "OpenAI’s policy is that content you provide (data, drafts, ideas) is **not used to train models**. With ChatGPT:  \n",
    "\n",
    "- Your conversations remain private.  \n",
    "- You own the outputs generated.  \n",
    "- Intellectual ownership stays with you, unless the content itself is copyrighted by others.  \n",
    "\n",
    "For organizations with stricter requirements, **ChatGPT Enterprise** and **API versions** provide stronger assurances (no logging, enterprise-grade security).  \n",
    "This means that uploading a draft here does not constitute public disclosure, but ethically, you are still responsible toward co-authors, institutions, and funders.\n",
    "\n",
    "\n",
    "<u>**Q3. Patents:** Can I patent something if I exchanged with ChatGPT during the invention process?</u>\n",
    "\n",
    "Yes. Current patent law recognizes only **human inventors**. AI is considered a tool, not a co-inventor. The key condition is that the inventive step was under your intellectual control.  \n",
    "\n",
    "**Points to consider:**  \n",
    "- Using ChatGPT does **not** count as public disclosure under current policies.  \n",
    "- A public disclosure before filing may invalidate novelty.  \n",
    "- Risks arise if you share too much with third parties without protection.  \n",
    "\n",
    "**Best practice:** Document your own creative contribution, file the patent before publication, and consult your institution’s **tech transfer office**.\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "### Useful links\n",
    "\n",
    "<div class=\"rqT\" title=\"Wanna know more (in French) ?\">\n",
    "\n",
    "[Lire l'excellent article de l'INSERM, \"Recommandations de bonnes pratiques suite à l’analyse des questions éthiques soulevées par l’utilisation de\n",
    "l’Intelligence Artificielle dans la recherche à l’Inserm\" (**2025**)](https://inserm.hal.science/inserm-04975393v1)\n",
    "\n",
    "[Voir l'épisode de la formation Fidle du CNRS consacré à \"IA, droit, société et éthique : Vivre avec l'IA !\" (**Saison 2024/2025**)](https://www.youtube.com/watch?v=qPEALuogSBg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc284a9-4e87-43db-9184-7cadd16862fc",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "<div class=\"introE\">\n",
    "\n",
    "<u>In short, here are a few aspects that deserve to be highlighted</u>\n",
    "\n",
    "- **Ethical AI is the foundation of trust**, and therefore of the sustainable adoption of these technologies in our societies.\n",
    "- Scientists must be cautious about the uncontrolled dissemination of data (**loss of confidentiality**) as well as the spread of unverified information (**hallucinations**, **unsourced data**), regardless of the digital tool used.\n",
    "- Researchers should explicitly **indicate the use of artificial intelligence systems in their work** (tools, algorithms, parameters) and distinguish between contributions obtained through these systems and those resulting from their own creative activity.\n",
    "- Scientists should promote models that **respect the citation of data sources** and encourage academic uses of **open science**.\n",
    "- Researchers are encouraged to thoroughly test the **reproducibility and reliability of AI models** by (1) comparing results obtained with different datasets, and (2) testing outcomes with different AI algorithms.\n",
    "- **Data generated with the help of AI must be clearly identified** to avoid any confusion with real observations.\n",
    "- A large language model (LLM, such as ChatGPT) mines vast amounts of text and is very effective at answering general questions, but its **responses are often of limited relevance when it comes to domain-specific expertise**.\n",
    "- In the field of **healthcare**, patients’ rights must be respected: professional secrecy and data confidentiality, prohibition of using data for research without prior information — or even the consent — of the individuals concerned, compliance with the GDPR (**General Data Protection Regulation**), the Digital Act, the **European Artificial Intelligence Act** (‘AI Act’), as well as other provisions of national law.\n",
    "- Like any technology, AI tools are never neutral, whether in their design phases or in their uses. They may have been trained on **data that do not reflect principles of fairness**, and may be shaped by choices and values that mirror the potential biases of their developers and their embedding in a political and social context.\n",
    "- The exponential use of AI systems is accompanied by an explosion in their **ecological footprint**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ca02b-feef-4a84-ae69-4ca291a3b2b7",
   "metadata": {},
   "source": [
    "## Tutorial: Dataset Bias & Model Fairness\n",
    "\n",
    "<div class=\"intro\">\n",
    "    \n",
    "Let's consider a data set that contains 1200 individuals who have applied to various jobs. Each of them is characterized by:\n",
    "\n",
    "- its `gender`\n",
    "- the total number of years of professional experience, `years_exp`\n",
    "- the `education` highest degree, encoded as an ordinal categorical variable: 0 = Bachelor, 1 = Master, 2 = PhD\n",
    "- a `test_score`, which is the result of a structured assessment (coding task, technical MCQ, lab/aptitude test, or standardized psychometric)\n",
    "- a `career_break_months`, that is sometimes associated to a lack of commitment or diminished capability\n",
    "- a `senior_hire` label, which is a binary target label for the \"senior position\" decision: 1 = hired/selected, 0 = not hired\n",
    "\n",
    "In this synthetic dataset, labels were generated with a historical-bias mechanism. A bias agains women has deliberately be encoded, so the `senior_hire` variable intentionally reflects potential unfairness. This is purely for teaching purposes and does not claim to represent real-world hiring practices agains women...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37053e-3f7d-45da-a43e-54095b3656c9",
   "metadata": {},
   "source": [
    "### Import useful libraries and read a synthetic biases database built specifically by ChatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e3ded-c316-4544-88e0-b114dd53cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./ML-data/hiring_synthetic_withBreak_en.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1dd23-7a0c-44ba-a8f6-1664bcc0a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc38991-69ba-4ddf-a528-b8df14ddae72",
   "metadata": {},
   "source": [
    "### Exploratory glance = Exploratory Data Analysis (EDA)\n",
    "\n",
    "<div class=\"intro\">\n",
    "\n",
    "**What it includes (typically):**\n",
    "\n",
    "- Structure & quality: schema, types, missing values, outliers, duplicates.\n",
    "- Distributions: histograms/boxplots, summary stats (mean, quartiles).\n",
    "- Relationships: scatterplots, correlations, crosstabs, group comparisons.\n",
    "- Balance & leakage checks: class imbalance, train/test splits, proxies for sensitive features.\n",
    "\n",
    "**Why it matters (here):**\n",
    "- Detect bias sources (e.g., group imbalances) and proxies for protected attributes.\n",
    "- Inform preprocessing choices (scaling, encoding, imputation) and fair metrics to monitor.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb86b7-f49c-4d2b-9177-2e6471a726bd",
   "metadata": {},
   "source": [
    "#### Basic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef66415-b20e-48b3-98a1-aab1d1690d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group counts\n",
    "group_counts = df['gender'].value_counts().sort_index()\n",
    "print(\"Counts by gender:\\n\", group_counts)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(group_counts.index, group_counts.values)\n",
    "plt.title('Counts by gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03d60e-f73f-41fe-bc26-18f78925972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years of experience by gender (overlaid histograms)\n",
    "f_vals = df[df['gender']=='F']['years_exp'].values\n",
    "m_vals = df[df['gender']=='M']['years_exp'].values\n",
    "\n",
    "f_av = f_vals.mean()\n",
    "m_av = m_vals.mean()\n",
    "f_std = f_vals.std()\n",
    "m_std = m_vals.std()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(f_vals, bins=20, alpha=0.4, label=f'F. {f_av:.1f} ± {f_std:.1f} years')\n",
    "plt.hist(m_vals, bins=20, alpha=0.4, label=f'M. {m_av:.1f} ± {m_std:.1f} years')\n",
    "plt.title('Years of experience by gender')\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbb8f2-a776-4606-a91c-cf2f2bd29f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Career break\n",
    "f_vals = df[df['gender']=='F']['career_break_months'].values\n",
    "m_vals = df[df['gender']=='M']['career_break_months'].values\n",
    "\n",
    "f_av = f_vals.mean()\n",
    "m_av = m_vals.mean()\n",
    "f_std = f_vals.std()\n",
    "m_std = m_vals.std()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(f_vals, bins=20, alpha=0.6, label=f'F {f_av:.1f} ± {f_std:.1f}')\n",
    "plt.hist(m_vals, bins=20, alpha=0.6, label=f'M {m_av:.1f} ± {m_std:.1f}')\n",
    "plt.title('Career break by gender')\n",
    "plt.xlabel('Duration / months')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5865ea-c65c-48bb-9daf-0e137f6ed188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score by gender\n",
    "f_vals = df[df['gender']=='F']['test_score'].values\n",
    "m_vals = df[df['gender']=='M']['test_score'].values\n",
    "\n",
    "f_av = f_vals.mean()\n",
    "m_av = m_vals.mean()\n",
    "f_std = f_vals.std()\n",
    "m_std = m_vals.std()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(f_vals, bins=20, alpha=0.6, label=f'F {f_av:.1f} months ± {f_std:.1f}')\n",
    "plt.hist(m_vals, bins=20, alpha=0.6, label=f'M {m_av:.1f} months ± {m_std:.1f}')\n",
    "plt.title('Test score by gender')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa365d5-f41a-4732-a4a0-ab07b709d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education distribution by gender (bar chart) — 0=Bachelor, 1=Master, 2=PhD\n",
    "tab = pd.crosstab(df['education'], df['gender'])\n",
    "print(tab)\n",
    "\n",
    "plt.figure()\n",
    "index = np.arange(tab.shape[0])\n",
    "width = 0.35\n",
    "plt.bar(index - width/2, tab['F'].values, width, label='F')\n",
    "plt.bar(index + width/2, tab['M'].values, width, label='M')\n",
    "plt.xticks(index, ['Bachelor','Master','PhD'])\n",
    "plt.xlabel('Education level')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Education distribution by gender')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72db146-8898-4b5e-a812-a81f5548d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Senior hire\n",
    "n = len(df)\n",
    "rate_overall = df[\"senior_hire\"].mean()\n",
    "by_gender = df.groupby(\"gender\")[\"senior_hire\"].mean().to_dict()\n",
    "counts_by_gender = df[\"gender\"].value_counts().to_dict()\n",
    "\n",
    "print(f\"n = {n}\")\n",
    "print(\"Counts by gender:\", counts_by_gender)\n",
    "print(f\"Hire rate overall: {rate_overall*100:.1f}%\")\n",
    "print(\"Hire rate by gender:\", {k: f\"{v:.1%}\" for k, v in by_gender.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e805fd-aa01-44f3-a2d5-d7b145a5ce62",
   "metadata": {},
   "source": [
    "<div class='rqE'>\n",
    "\n",
    "The senior hire rate is gender dependent!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9144de-317c-4f51-932f-3430ff65549e",
   "metadata": {},
   "source": [
    "#### Is the lower senior hire rate for women merit- and professional experience-related?\n",
    "\n",
    "<div class=\"intro\">\n",
    "\n",
    "To answer this question, let's define a \"latent merit\" function. Think of latent merit as an unobserved suitability score for the senior job, independent of the gender. Let's define it as:\n",
    "\n",
    "$$f_{\\mathrm{hire\\_score}}=0.5\\times\\mathrm{years\\_exp}+4\\times\\mathrm{education}+0.07\\times\\mathrm{test\\_score}+ε$$\n",
    "\n",
    "where *&epsilon;* is a noise ∼&Nscr;(0,2)\n",
    "\n",
    "(&Nscr;(*&mu;*, *&sigma;*<sup>2</sup>) means Normal with mean *&mu;* and standard deviation *&sigma;*)\n",
    "\n",
    "(the 0.5, 4 and 0.07 factors are chosen so that the three inputs contribute on similar magnitudes to the latent score, given their natural ranges).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7726c-3373-4686-a11c-3e6f4b1e158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_merit(x):\n",
    "    rng = np.random.default_rng(42) #NumPy’s modern way to create a random-number generator\n",
    "    years_exp = x[\"years_exp\"]\n",
    "    education = x[\"education\"]\n",
    "    test_score = x[\"test_score\"]\n",
    "    return round(0.5*years_exp + 4*education + 0.07*test_score + rng.normal(0, 2.0),1)\n",
    "\n",
    "df[\"hire_score\"] = df.apply(latent_merit, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f644cc3-40e8-45c2-abc4-df015a195dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vals = df[df['gender']=='F']['hire_score'].values\n",
    "m_vals = df[df['gender']=='M']['hire_score'].values\n",
    "\n",
    "f_av = f_vals.mean()\n",
    "m_av = m_vals.mean()\n",
    "f_std = f_vals.std()\n",
    "m_std = m_vals.std()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(f_vals, bins=30, alpha=0.6, label=f\"F {f_av:.1f} ± {f_std:.1f}'\")\n",
    "plt.hist(m_vals, bins=30, alpha=0.6, label=f\"M {m_av:.1f} ± {m_std:.1f}'\")\n",
    "plt.title(\"Hire score distributions (latent)\")\n",
    "plt.xlabel(\"Hire score (latent merit + noise)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65fda14-5f20-4157-8508-acd45bdfd7d7",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "What the “Hire score distributions (latent)” plot reveals:\n",
    "- It shows the histograms of the latent merit for F and M.\n",
    "- The two distributions overlap heavily, which is what we expect if the underlying merit is similar across groups.\n",
    "- The disparity in hiring does not come from merit differences; it comes from the decision rule (the higher threshold applied to women).\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"intro\">\n",
    "\n",
    "Let's save the the new dataset, *i.e.* with the additional `hire_score` column\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c91d8-bb68-45d2-9fc4-0396b017861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./ML-data/hiring_synthetic_en_with_hire_score.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a1137-8729-4b9b-a917-9d57674647f5",
   "metadata": {},
   "source": [
    "#### Is there an obvious correlation between `hire_score` and `senior_hire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688127bc-ce72-4221-a111-0e43de7ad653",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df[df['gender']=='F'][\"hire_score\"],df[df['gender']=='F'][\"senior_hire\"],ls=\"\",marker=\"o\", ms=10,color=\"orange\", label=\"F\")\n",
    "plt.plot(df[df['gender']=='M'][\"hire_score\"],df[df['gender']=='M'][\"senior_hire\"],ls=\"\",marker=\"p\", color=\"green\", label=\"M\")\n",
    "plt.xlabel(\"merit (hire_score)\")\n",
    "plt.ylabel(\"senior_hire\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178026c-f0d2-44ee-bea8-48acbd057c88",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "- There are more low merit men who have been hired than low merit women \n",
    "- It will probably be better to try make a prediction of the hiring score as a function of the individual parameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77969451-50b9-4e8c-937a-1978514612ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df[df['gender']=='F'][\"career_break_months\"],df[df['gender']=='F'][\"senior_hire\"],ls=\"\",marker=\"o\", ms=10,color=\"orange\", label=\"F\")\n",
    "plt.plot(df[df['gender']=='M'][\"career_break_months\"],df[df['gender']=='M'][\"senior_hire\"],ls=\"\",marker=\"p\", color=\"green\", label=\"M\")\n",
    "plt.xlabel(\"career break / months\")\n",
    "plt.ylabel(\"senior_hire\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ea668-9cf4-4dbc-b29e-d4b4deccf693",
   "metadata": {},
   "source": [
    "### Hey ChatGPT, I need you to make automatic senior hiring decisions\n",
    "\n",
    "#### First: make a workflow\n",
    "\n",
    "<div class=\"intro\">\n",
    "\n",
    "**Hi ChatGPT, here is my dataset. Can you help me build a model to predict senior hiring based on `years_exp`, `education` and `test_score`?**\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"rqT\">\n",
    "    \n",
    "**Goal.** Train a simple model that uses three parameters to predict the binary label `senior_hire`.\n",
    "\n",
    "We will:\n",
    "1) load the data;\n",
    "2) split into train/test;\n",
    "3) fit a logistic regression with class balancing;\n",
    "4) evaluate;\n",
    "5) optionally tune the decision threshold in order to minimize the number of false positive and false negative, if relevant;\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b22852-fa89-4f61-9f0f-883e3a3bdb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./ML-data/hiring_synthetic_en_with_hire_score.csv')\n",
    "display(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e583c-fa90-4976-86cd-e851d14b927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve,\n",
    "    average_precision_score, precision_recall_curve\n",
    ")\n",
    "\n",
    "X = df[[\"years_exp\",\"education\",\"test_score\",\"career_break_months\"]].copy()\n",
    "y = df[\"senior_hire\"].astype(int).copy()\n",
    "\n",
    "print(X,y)\n",
    "\n",
    "print(f\"Dataset size: {len(df)} | Positives: {int(y.sum())} ({y.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9774aad-1a2c-4fc5-a05b-e044cabd3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Train/test split (stratify keeps class balance)\n",
    "# if you have 100 of class1 and 100 of a class2 , when you split with 0.2 test size\n",
    "# you will get a train set with 80 of class1 and 80 of class2 and a test set of 20 of class1 and 20 of class2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48888831-bbfb-4643-915c-eab64cc36250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Preprocess + model\n",
    "num_cols = [\"years_exp\",\"test_score\",\"career_break_months\"]\n",
    "cat_cols = [\"education\"]  # ordinal encoded as 0/1/2\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(categories=[[0,1,2]], drop=\"first\", handle_unknown=\"ignore\"), cat_cols)\n",
    "])\n",
    "\n",
    "# `class_weight=\"balanced\"` helps if positives are rarer\n",
    "clf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f93a4c-0b38-435d-8cf1-61193c6b0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Evaluation at the default 0.5 probability threshold\n",
    "threshold_hire = 0.5 #senior_hire = F below this threshold\n",
    "proba_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_hired = (proba_test >= threshold_hire).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_hat_hired)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat_hired, average=\"binary\", zero_division=0)\n",
    "cm = confusion_matrix(y_test, y_hat_hired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a906f-8c1d-4e2b-b16b-c3b70bc12dd9",
   "metadata": {},
   "source": [
    "<div class='rqE'>\n",
    "\n",
    "**Why `y_hat_hired = (proba_test >= 0.5)`?**\n",
    "\n",
    "- The model (logistic regression) outputs probabilities: proba_test = clf.predict_proba(X_test)[:,1] → values in [0,1]\n",
    "- Many metrics (accuracy, precision, recall, confusion matrix) need class labels (0/1), not probabilities.\n",
    "\n",
    "So we threshold the probabilities to get labels\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89558941-86c6-4822-a38c-e626a1060a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic metrics (need both classes in test)\n",
    "roc_auc = roc_auc_score(y_test, proba_test)\n",
    "pr_auc = average_precision_score(y_test, proba_test)\n",
    "\n",
    "print(f\"=== Test metrics @ threshold = {threshold_hire} ===\")\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"PR-AUC:    {pr_auc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "plt.figure()\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(f\"Confusion matrix (threshold = {threshold_hire})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af4382-2bf3-455c-bcec-b9cc690a6688",
   "metadata": {},
   "source": [
    "#### Hey ChatGPT, is there a gender issue in this prediction?\n",
    "\n",
    "<div class=\"rqE\">\n",
    "\n",
    "Dropping gender from the dataset doesn’t stop the model from inferring it from proxies.\n",
    "\n",
    "<u>Quick examples for proxies:</u>\n",
    "- Zip code / district → proxy for ethnicity or income\n",
    "- Career break length / part-time history → proxy for gender/parental status\n",
    "- First name / given name → proxy for gender or ethnicity\n",
    "- Education pedigree / test language → proxy for socio-economic background\n",
    "- Wearable/phone model → proxy for income/age\n",
    "</div>\n",
    "\n",
    "##### How to infer proxies?\n",
    "\n",
    "<div class=\"intro\">\n",
    "\n",
    "Let's calculate the AUC score, that summarizes how well a model’s scores separate classes as you sweep the decision threshold from 0 → 1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5aa904-109f-4e81-9168-652f5488f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del clf\n",
    "\n",
    "y_gender = df['gender'].map({'F':0,'M':1})\n",
    "\n",
    "num_cols = [\"years_exp\",\"test_score\",\"career_break_months\"]\n",
    "cat_cols = [\"education\"]  # ordinal encoded as 0/1/2\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(categories=[[0,1,2]], drop=\"first\", handle_unknown=\"ignore\"), cat_cols)\n",
    "])\n",
    "\n",
    "# `class_weight=\"balanced\"` helps if positives are rarer\n",
    "clf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "display(clf)\n",
    "\n",
    "Xtr,Xte,ytr,yte = train_test_split(X, y_gender, stratify=y_gender, random_state=42)\n",
    "clf.fit(Xtr,ytr)\n",
    "auc = roc_auc_score(yte, clf.predict_proba(Xte)[:,1])\n",
    "pr_auc  = average_precision_score(yte, clf.predict_proba(Xte)[:,1])\n",
    "print(\"Can we infer gender from X?\")\n",
    "print(f\"ROC-AUC={auc:.2f}\")  \n",
    "print(f\" PR-AUC={pr_auc:.2f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b23c4c-8c8e-433b-98ca-bfdefd1186aa",
   "metadata": {},
   "source": [
    "<div class='rqE'>\n",
    "\n",
    "The results (ROC-AUC ≈ 0.97, PR-AUC ≈ 0.97) mean that gender is now highly inferable from X. In other words, there is a very strong proxy - almost surely the `career_break_months` descriptor. Dropping gender won’t protect women; the model can reconstruct it from these features\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd35c3-9449-4812-a9c2-08d6dcab1916",
   "metadata": {},
   "source": [
    "<div class=\"exE\", title=\"Which is the proxy?\">\n",
    "    \n",
    "Check that `career_break_months` is actually a strong proxy for `gender`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa13bdc-2c69-411d-a636-7b29a89a20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abec67-d3c6-4984-baf2-70f5d2875ae6",
   "metadata": {},
   "source": [
    "<div class=\"sol\">\n",
    "\n",
    "Do you want a possible solution to this exercise? Uncomment the command `# %load ./SolutionsToExercises/...` below\n",
    "\n",
    "(*you need to run the cell contents twice: the first time to load the Python file, and the second time to execute the Python code that was loaded*).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44a122-efb4-48d7-b805-3072c1277d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./SolutionsToExercises/ML/proxy_career_gender.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998a632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vID.end(cwd0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422d77b-9849-45c3-93a3-7752bdd0b92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
