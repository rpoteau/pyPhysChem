{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8735ac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/romuald/ENSEIGNEMENT/1-JupyterNotebooks/pyPhysChem/ImageProcessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: bold;\n",
       "}\n",
       "body, intro, introE, introT, rq, rqE, rqT, ex, exE, app, appE, sol, todo, hint, hintE, figure  {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: 400;\n",
       "  font-size: 12px;\n",
       "}\n",
       "h1 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 30px ;\n",
       "  color: white;\n",
       "  background: #b11d01;\n",
       "  text-align: center;\n",
       "}\n",
       "h2 {\n",
       "  border: 3px solid #333;\n",
       "  padding: 18px ;\n",
       "  color: #b11d01;\n",
       "  background: #ffffff;\n",
       "  text-align: center;\n",
       "}\n",
       "h3 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 12px ;\n",
       "  color: #000000;\n",
       "  background: #c1c1c1;\n",
       "  text-align: left;\n",
       "}\n",
       "h4 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #d9fffc;\n",
       "  text-align: left;\n",
       "}\n",
       "h5 {\n",
       "  border: 1px solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #ffffff;\n",
       "  text-align: left;\n",
       "}\n",
       ".introT::before {    \n",
       "    content: attr(title);\n",
       "    background-color: #cecece;\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".introT {    \n",
       "    background-color: #cecece80;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".intro {    \n",
       "    background-color: #cecece80;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".introE {    \n",
       "    background-color: #cecece80;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "    color : #117996;\n",
       "}\n",
       ".rq::before {    \n",
       "    background-color: #fcd3d3;\n",
       "    color: #ff0000;\n",
       "    content:\"Remarque\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".rq {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".rqE::before {    \n",
       "    background-color: #fcd3d3;\n",
       "    color: #ff0000;\n",
       "    content:\"Pay attention\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".rqE {    \n",
       "    background-color: #fcd3d380;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".rqT::before {    \n",
       "    background-color: #fcd3d3;\n",
       "    color: #ff0000;\n",
       "    content: attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".rqT {    \n",
       "    background-color: #fcd3d380;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".exold {    \n",
       "    background-color: #b2dbea80;\n",
       "    border-color: #0055ff;\n",
       "    border-left: 10px solid #0055ff;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".ex {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".ex::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Exercice. \" attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".exE {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "    color : #117996;\n",
       "}\n",
       ".exE::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Exercise. \" attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "    color : #117996;\n",
       "}\n",
       ".hint {    \n",
       "    background-color: #dede6f80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "    color : ##37665f;\n",
       "}\n",
       ".hint::before {\n",
       "    background-color: #dede6f;\n",
       "    content:\"Indice(s). \" attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "    color : ##37665f;\n",
       "}\n",
       ".hintE {    \n",
       "    background-color: #dede6f80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "    color : ##37665f;\n",
       "}\n",
       ".hintE::before {\n",
       "    background-color: #dede6f;\n",
       "    content:\"Hint(s). \" attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "    color : ##37665f;\n",
       "}\n",
       ".app {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".app::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Application\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".appE {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    color : #117996;\n",
       "    position:relative;\n",
       "}\n",
       ".appE::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Application\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    color : #117996;\n",
       "    display: block;\n",
       "}\n",
       ".solFr {    \n",
       "    background-color: #bbeab880;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".solFr::before {\n",
       "    background-color: #bbeab8;\n",
       "    content:\"Solution\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}.sol {    \n",
       "    background-color: #bbeab880;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".sol::before {\n",
       "    background-color: #bbeab8;\n",
       "    content:\"Answer\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".com {    \n",
       "    background-color: #ffff7f80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".com::before {\n",
       "    background-color: #ffff7f;\n",
       "    content:\"Comment.\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       "div.todo:before {\n",
       "    content:url(data:image/png;base64,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);\n",
       "    float:left;\n",
       "    margin-left:20px;\n",
       "    margin-right:20px;\n",
       "    margin-top:20px;\n",
       "    margin-bottom:20px;\n",
       "}\n",
       "div.todo{\n",
       "    font-size: 1.1em;\n",
       "    margin-top:40px;\n",
       "    background-color: #b2dbea80;\n",
       "}\n",
       "div.todo ul{\n",
       "    margin: 0.2em;\n",
       "}\n",
       "div.todo li{\n",
       "    margin-left:60px;\n",
       "    margin-top:0;\n",
       "    margin-bottom:0;\n",
       "}\n",
       "\n",
       "figure {\n",
       "    border: 0px;\n",
       "    text-align: center;\n",
       "    margin: 5px; /* adjust as needed */\n",
       "    display: block;\n",
       "    margin: auto;\n",
       "}\n",
       "figure img {\n",
       "    vertical-align: top;\n",
       "    text-align: center;\n",
       "    display: block;\n",
       "    margin: auto;\n",
       "}\n",
       "figure figcaption {\n",
       "    border: 0px;\n",
       "    text-align: center;\n",
       "    font-size: 11px;\n",
       "    margin: auto;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Start at:** Thursday 02 October 2025, 22:15:19  \n",
       "**Hostname:** device-8.home (Linux)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"../config/svg/pyPhysChemBanner.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "cwd0 = '../config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID_Eng as vID\n",
    "from visualID_Eng import fg,bg,hl,color\n",
    "vID.init(cwd0)\n",
    "\n",
    "import tools4pyPhysChem as t4pPC\n",
    "\n",
    "#cancel the \"last show-up\" behaviour of Jupyter notebooks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "__author__ = \"Simon Cayez, LPCNO / Département Génie Physique (INSA Toulouse, France)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a90d06",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">\n",
    "  <b><u>Dataset Preparation</u>:<br>\n",
    "  Step 1 – Image Processing</b>\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a988a5",
   "metadata": {},
   "source": [
    "## Context\n",
    "  \n",
    "<div class=\"intro\">\n",
    "\n",
    "In this workshop, we will work on **µSAXS (Micro-Small-Angle X-Ray Scattering)** data collected at the SOLEIL synchrotron, beamline SWING, from the following paper:\n",
    "\n",
    "Chaâbani, W.; Lyu, J.; Marcone, J.; Goldmann, C.; ten Veen, E. J. M.; Dumesnil, C.; Bizien, T.; Smallenburg, F.; Impéror-Clerc, M.; Constantin, D.; Hamon, C. *Prismatic Confinement Induces Tunable Orientation in Plasmonic Supercrystals.* **ACS Nano** 2024, 18 (13), 9566-9575.  \n",
    "[https://doi.org/10.1021/acsnano.3c12799](https://doi.org/10.1021/acsnano.3c12799)  \n",
    "[pdf version](https://drive.google.com/file/d/1mMho8MjkwT_7HqI2QKEkG25SVLtqYgvI/view?usp=drive_link)\n",
    "\n",
    "The study investigates how to control the **orientation of plasmonic supercrystals** (assemblies of gold nanorods ≈60 nm long and ≈25 nm in diameter) by using **“prismatic confinement”** — templates with polygonal (triangle, square, circle…) cross-sections.  \n",
    "These anisotropic gold nanoparticles were synthesized by a standard seed-mediated growth method, producing well-defined rods with tunable aspect ratios.\n",
    "\n",
    "Prismatic templates made of PDMS were filled with a **liquid suspension of nanorods**, then the solvent was removed by **evaporation-induced self-assembly (EISA)**.  \n",
    "This confinement + EISA process drives the rods to organize into **oriented supercrystals** whose texture depends on the template geometry.  \n",
    "The resulting structures were characterized by **µSAXS at  synchrotron SOLEIL** to reveal domain orientation and defects at the ensemble scale.\n",
    "\n",
    "\n",
    "- **Prismatic templates** (PDMS with polygonal cavities) combined with **evaporation-induced self-assembly** enable reproducible orientation of anisotropic nanoparticles into supercrystals.  \n",
    "- **Each edge of the cavity defines a monodomain orientation**; controlling the cavity geometry = controlling the texture of the supercrystal.  \n",
    "- **µSAXS at a synchrotron** bridges the gap between local (SEM) and ensemble (full SAXS) characterization — key for understanding domain orientation and defects.  \n",
    "- This combined approach provides a **scalable, low-cost way to design metasurfaces** with tunable optical properties.  \n",
    "<br>\n",
    "<!-- Tableau pour l'image principale, sans bordures -->\n",
    "<table style=\"border-collapse:collapse; border:none; margin-left:auto; margin-right:auto;\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:center; border:none;\">\n",
    "      <img src=\"figures/fig0.png\" width=\"800\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"border-collapse:collapse; border:none; margin-left:auto; margin-right:auto; width:800px;\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:justify; font-size:14px; border:none;\">\n",
    "      <i>\n",
    "        <b>Fig. 0. A)</b>  <br><br>\n",
    "        <b>B)</b> Schematic view of the templated EISA process.<br>\n",
    "        <b>B)</b> Schematic description of the geometry and size of microcavities<br>\n",
    "        <b>C)</b> Optical microscopy image of a superlattice of\n",
    "triangular SCs obtained after template-assisted self-assembly and peeling off the PDMS\n",
    "template. The red frame shows the typical footprint of the conventional SAXS beam and the\n",
    "blue one that of the μSAXS beam, which also corresponds to the size of an SEM image.<br>\n",
    "        <b>D-E)</b> SEM images of an AuNR triangular geometrys.<br>\n",
    "        <b>E)</b> Au Nanorods organization in the mold<br>\n",
    "        <b>F)</b> Two-dimensional SAXS images acquired on different zones of the sample consisting of AuNR\n",
    "supercrystals with different cross-section.\n",
    "      </i>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "We will work with a dataset of **1800 images** in **3 folders** named **\"circle\", \"triangle\" and \"square\"** with around 600 µSAXS images for each geometry.  The aim is to **prepare the dataset** in order to use it for **deep learning** image **classification** with a 2D Convolutional Network.  \n",
    "Building the dataset is a key point for the success of all machine learning processes. It is common to obtain bad predictions due to poor data preparation.\n",
    "The steps will be:  \n",
    "\n",
    "\n",
    "- **Extract** images from structured *.nxs or *.h5 files  \n",
    "- Build **NumPy array**s containing images  \n",
    "- **Reshape** the NumPy arrays  \n",
    "- Explore the dataset by sample **image visualization** \n",
    "- Explore and adapt **pixel values** \n",
    "- **Crop** images  \n",
    "- Visualize the dataset as a **video**  \n",
    "- **Normalize** pixels in the range 0–1  \n",
    "- **Resize** images  \n",
    "- **Concatenate** the data from circle, square, and triangle to build X  \n",
    "- Create a **labels** array  \n",
    "- **Shuffle** the data  \n",
    "- **Split** the data into **train and test** sets  \n",
    "- Prepare a **Convolutional Neural Network**  \n",
    "- **Train** it  \n",
    "- Make **predictions** on the test dataset  \n",
    "- **Evaluate** the quality of the model\n",
    "\n",
    "---\n",
    "\n",
    "In our dataset, we have **three classes** corresponding to the mold geometries:  \n",
    "\n",
    "- `circle`  \n",
    "- `triangle`  \n",
    "- `square`  \n",
    "\n",
    "In this workshop, we will process each class **separately** to explore and manipulate the images.  \n",
    "In the **next notebook** , we will **combine all classes** to build a complete dataset suitable for training a neural network.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec7097",
   "metadata": {},
   "source": [
    "### Workflow Roadmap\n",
    "\n",
    "<div class=\"intro\">\n",
    "\n",
    "The figures below provides a visual **roadmap** of the steps we will follow during the workshop.  \n",
    "Each block corresponds to a key stage in the data preparation.  \n",
    "Variable names, functions, and loops that you will encounter in the notebook are already indicated inside the diagrams.  \n",
    "\n",
    "This roadmap will help you:\n",
    "- Understand the overall workflow  \n",
    "- See how individual steps (data extraction, reshaping, visualization, normalization, model building, training, evaluation…) connect to each other,\n",
    "- Quickly locate where a variable or function will be used in the code.\n",
    "\n",
    "You can refer back to this roadmap at any time as you progress through the notebook.\n",
    "<br>\n",
    "<table style=\"border-collapse:collapse; border:none; margin-left:auto; margin-right:auto;\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:center; border:none;\">\n",
    "      <img src=\"figures/fig7.png\" width=\"450\">\n",
    "    </td>\n",
    "    <td style=\"text-align:center; border:none;\">\n",
    "      <img src=\"figures/fig8.png\" width=\"450\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b512b4",
   "metadata": {},
   "source": [
    "## 1- Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e60362",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "    \n",
    "In synchrotron facilities, experimental data are stored in **NeXus (`.nxs`) files**, which are based on the HDF5 format.  \n",
    "These files contain a large amount of structured information (metadata, instrument settings, measurement results, etc.).  \n",
    "\n",
    "For this workshop, we are interested only in the **images** recorded during the experiment.  \n",
    "To simplify the workflow, we used a helper function called `extract_nxs_folder` (defined in `extract.py`).  \n",
    "This function reads all the `.nxs` files inside a specified folder and **extracts** the corresponding images into **NumPy arrays** that we can process further.\n",
    "\n",
    "The full process is detailed in the notebook [nxs_extraction.ipynb](nxs_extraction.ipynb)  \n",
    "\n",
    "With this [example of *.nxs file](https://drive.google.com/file/d/1AVqtR9f7KmtOwyNWw4nsCeyT0ASxG2IW/view?usp=drive_link) , you can quickly **preview the content of a `.nxs`/`.h5` file without writing code**, you can use the free online viewer provided by the HDF Group: [https://myhdf5.hdfgroup.org/](https://myhdf5.hdfgroup.org/).  \n",
    "  \n",
    "A small sample of  original `*.nxs files` is available at this [link](https://drive.google.com/drive/folders/1r7WzPfk0DzZjrfgaC5OcpNfCHPYGTvFh?usp=drive_link) for a future test of  [nxs_extraction.ipynb](nxs_extraction.ipynb)  \n",
    "\n",
    "To avoid manipulating large amont of heavy `*.nxs` files, all the conversion were done before the workshop. We will then start from Numpy arrays.  \n",
    "For the first steps <u>download only `square_raw.npy` and place it in the folder `data`</u>.   \n",
    "\n",
    "- `square_raw.npy`[download](https://drive.google.com/file/d/11VUCyEgwYiCDk1qwRf7gep7PZEcbfTy3/view?usp=drive_link)\n",
    "- `triangle_raw.npy`[download](https://drive.google.com/file/d/1Ym_e5zN9spUv9dv5-8SNUtwajLQzXKeW/view?usp=drive_link)\n",
    "- `circle_raw.npy`[download](https://drive.google.com/file/d/1cAirdyB0nsuZEGLMetmh3y2oklF8PNg9/view?usp=drive_link)\n",
    "\n",
    "> ⚠️ When downloading, Google Drive may display a warning message:  \n",
    "> *\"Google Drive cannot scan this file for viruses. Do you want to download anyway?\"*  \n",
    "> The file is large (XX MB), so this is normal. **Please trust the source and continue with the download.**  \n",
    "\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"app\">\n",
    "\n",
    "Open the file square_raw.npy contained in folder (variable name : `data_raw`)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c116f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f249b5a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "geometry = 'square'\n",
    "file_path = f\"data/{geometry}_raw.npy\"\n",
    "data_raw = np.load(file_path)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb605e3",
   "metadata": {},
   "source": [
    "## 2- Explore data format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2910303",
   "metadata": {},
   "source": [
    "### 2-1 Shape and dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1271ff0",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "\n",
    "Inspect the **number of dimensions** and the **shape** of the NumPy array to understand its structure (how many images and their size)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7381dd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "# Check the number of dimensions and the shape of the array\n",
    "print(f\"Number of dimensions : {data_raw.ndim}\")\n",
    "print(f\"Shape  : {data_raw.shape}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a78122",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "The loaded NumPy array has shape **(n, 1083, 1035)**:\n",
    "\n",
    "- **n** = number of images  \n",
    "- **1083** = image height (pixels)  \n",
    "- **1035** = image width (pixels)\n",
    "\n",
    "It is therefore a **3-D** array where each slice along the first axis is one image of **size 1083×1035 pixels**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b842813",
   "metadata": {},
   "source": [
    "### 2-2 Plot images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c691e",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "\n",
    "In this section, we will focus on **visualizing the µSAXS images** we extracted and preprocessed.  \n",
    "\n",
    "Since the dataset can contain **large numbers of high-resolution images**, it is important to explore them efficiently and to check for any unexpected artifacts or anomalies.  \n",
    "</div>\n",
    "<br>\n",
    "<div class=\"app\">\n",
    "We will use **Matplotlib**, a Python library for plotting graphs and displaying images, to visualize our dataset.  \n",
    "\n",
    "Since `first_channels` is a NumPy array containing multiple images, we **slice the array** to select only the first image (`index 0`) for display.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3814c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea8bc7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Display the first image in the first_channels array\n",
    "# raw_data[0, :, :] selects the first image (all rows and columns)\n",
    "# cmap='gray' ensures the image is shown in grayscale\n",
    "ax.imshow(data_raw[0, :, :],cmap='gray')\n",
    "ax.set_title(\"First image raw\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcaf688",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "    \n",
    "We can also display **multiple images side by side** to compare them easily.  \n",
    "Here, we will show the first three images from `first_channels` using subplots in Matplotlib.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ecd40",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "# Create a figure with 1 row and 3 columns of subplots\n",
    "# figsize=(15,5) sets the width and height of the figure in inches\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "# Loop over the first three images\n",
    "for i in range(3):\n",
    "    # Display the i-th image in grayscale on the corresponding subplot\n",
    "    axes[i].imshow(data_raw[i, :, :],cmap='gray')\n",
    "    # Add a title to each subplot\n",
    "    axes[i].set_title(f\"Image {i} raw\")\n",
    "plt.show();\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d7b4d",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "    \n",
    "On the images we just plotted, you may notice that the scattering patterns are **hard to see**: most of the pixels have relatively low intensity values, while a few pixels are very bright.  \n",
    "\n",
    "In SAXS experiments, the intensity of scattered X-rays can **span several orders of magnitude**. Using a **logarithmic scale** allows us to:\n",
    "\n",
    "- Better visualize **both low and high intensity regions** in the same image  \n",
    "- Highlight subtle features in the scattering patterns that would otherwise be invisible  \n",
    "</div>\n",
    "<br>\n",
    "<div class=\"intro\">\n",
    "Next, we will apply a logarithmic transformation to the images to make the structures more apparent.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bbb6f",
   "metadata": {},
   "source": [
    "### 2-3- Log scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ab99c",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "    \n",
    "Plot the log of the intensity of 3 first images \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ea8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99907ecf",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "for i in range(3):\n",
    "    # np.log1p(x) computes log(1 + x) to avoid log(0) and enhance contrast\n",
    "    axes[i].imshow(np.log1p(data_raw[i, :, :]),cmap='gray') \n",
    "    axes[i].set_title(f\"Log image {i}\")\n",
    "plt.show();\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4056a",
   "metadata": {},
   "source": [
    "#### 2-3-1- Apply Logarithmic Transformation to the Data\n",
    "\n",
    "<div class=\"intro\">\n",
    "\n",
    "So far, we have only **visualized** the images using a logarithmic scale, but the underlying NumPy array **has not been modified**.  \n",
    "\n",
    "To enhance contrast and better handle the wide range of intensities in µSAXS images, we will now **apply a logarithmic transformation directly to the NumPy array**.  \n",
    "This will update the data itself, so subsequent processing (normalization, resizing, or feeding into a neural network) will use the transformed values.  \n",
    "We typically use `np.log1p()` to safely compute `log(1 + x)`, which avoids issues with zero-intensity pixels.\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div class=\"app\">\n",
    "\n",
    "Apply a logarithmic transformation to data_raw (variable name : `data_log`)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc61f65",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "data_log = np.log1p(data_raw)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14f651",
   "metadata": {},
   "source": [
    "#### 2-3-2- Image statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ec537",
   "metadata": {},
   "source": [
    "##### 📝 Exercise: Print Image Statistics\n",
    "\n",
    "<div class=\"app\">\n",
    "\n",
    "Write a function `print_image_stats(data, image_index=0)` that:  \n",
    "- selects one image from a NumPy array `(n_images, width, height)`  \n",
    "- computes **min**, **max**, **mean**, **median** pixel values  \n",
    "- prints them clearly  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c8bfe",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>🐢⏳ I'm stuck...</summary>\n",
    "\n",
    "<div class=\"intro\">\n",
    "**Goal:** Create a function that prints the **minimum, maximum, mean, and median** pixel values of a selected image in a dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `print_image_stats`\n",
    "- **Arguments:**\n",
    "  - `data` : a NumPy array of shape `(n_images, width, height)`  \n",
    "  - `image_index` : the index of the image to analyze (default: 0)\n",
    "- **Returns:**  \n",
    "  - Nothing, only prints the statistics in a clear format\n",
    "\n",
    "**Steps:**\n",
    "1. Select the image at `image_index` from `data`.\n",
    "2. Compute the `min`, `max`, `mean`, and `median` values of the image.\n",
    "3. Print them in a readable table format.\n",
    "\n",
    "**Example of usage**\n",
    "print_image_stats(data, image_index=0)\n",
    "\n",
    "**Example of expected print output (numbers are illustrative):**\n",
    "<pre>\n",
    "Statistic Value\n",
    "Min 0.0000  \n",
    "Max 123.4567  \n",
    "Mean 12.3456  \n",
    "Median 10.0000  \n",
    "</pre>\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c249569",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "def print_image_stats(data, image_index=0):\n",
    "    \"\"\"\n",
    "    Print min, max, mean, median of a 2D image within a 3D array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        3D array of images (N, H, W)\n",
    "    image_index : int, optional\n",
    "        Index of the image to analyze (default: 0)\n",
    "    \"\"\"\n",
    "    img = data[image_index, :, :]\n",
    "    print(f\"{'Statistic':<15} {'Value':>10}\")\n",
    "    print(\"-\" * 26)\n",
    "    print(f\"{'Min':<15} {np.min(img):>10.4f}\")\n",
    "    print(f\"{'Max':<15} {np.max(img):>10.4f}\")\n",
    "    print(f\"{'Mean':<15} {np.mean(img):>10.4f}\")\n",
    "    print(f\"{'Median':<15} {np.median(img):>10.4f}\")\n",
    "    print(50*'*')\n",
    "\n",
    "print_image_stats(data_raw, image_index=0)\n",
    "print_image_stats(data_log, image_index=0)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53025e4",
   "metadata": {},
   "source": [
    "### 2-4 Check all images with a video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf365cc",
   "metadata": {},
   "source": [
    "##### 📝 Exercise: Create a Video from Images  \n",
    "\n",
    "<div class=\"app\">\n",
    "    \n",
    "Write a function `create_video_from_images(images, output_path='output_video.mp4', fps=5)` that:  \n",
    "- takes a NumPy array `(n_images, height, width)`  \n",
    "- writes frames to a video file at `output_path` with `fps` frames/second\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f1dc6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>🐢⏳ I'm stuck...</summary>\n",
    "\n",
    "<div class=\"intro\">\n",
    "    \n",
    "**Goal:** Create a function that converts a sequence of images into a **video file** for fast visualization of the dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `create_video_from_images`  \n",
    "- **Arguments:**\n",
    "  - `images` : a NumPy array of shape `(n_images, height, width)`  \n",
    "  - `output_path` : path where the video file will be saved (default `'output_video.mp4'`)  \n",
    "  - `fps` : frames per second (speed of the video, default `5`)\n",
    "- **Returns:**  \n",
    "  - Nothing, the function should save a video file to `output_path`  \n",
    "- **Save the function in:** `visualization.py`\n",
    "\n",
    "**Steps:**\n",
    "1. Read the number of images and their dimensions from the array.  \n",
    "2. Create a `cv2.VideoWriter` object with the correct codec, frame size, and FPS.  \n",
    "3. Loop over the images, normalize pixel values to 0–255, convert to `uint8`, and write each frame to the video.  \n",
    "4. Release the `VideoWriter` and print a confirmation with the video details.\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```python\n",
    "# Create a video from the log-transformed dataset\n",
    "create_video_from_images(data_log, output_path='xxx.mp4', fps=5)\n",
    "```\n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670adbe0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "def create_video_from_images(images, output_path='output_video.mp4', fps=5):\n",
    "    \"\"\"\n",
    "    Create a video file from the image sequence\n",
    "    \n",
    "    Parameters:\n",
    "    images: numpy array of shape (n_images, height, width)\n",
    "    output_path: path to save the video file\n",
    "    fps: frames per second (speed of the video)\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    n_images, height, width = images.shape\n",
    "    \n",
    "    # Define video codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=False)\n",
    "    \n",
    "    print(f\"Creating video with {n_images} frames at {fps} FPS...\")\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        # Get current image and convert to float32\n",
    "        current_image = images[i, :, :].astype(np.float32)\n",
    "        \n",
    "        # Normalize image to 0-255 range\n",
    "        img_normalized = cv2.normalize(current_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        img_uint8 = img_normalized.astype(np.uint8)\n",
    "        \n",
    "        # Write frame to video file\n",
    "        out.write(img_uint8)\n",
    "        \n",
    "        # Show progress\n",
    "        if (i + 1) % 5 == 0 or i == 0 or i == n_images - 1:\n",
    "            print(f\"Processed frame {i+1}/{n_images}\")\n",
    "    \n",
    "    # Release the video writer\n",
    "    out.release()\n",
    "    print(f\"Video successfully saved as: {output_path}\")\n",
    "    print(f\"Video dimensions: {width}x{height}, Duration: {n_images/fps:.1f} seconds\")\n",
    "\n",
    "create_video_from_images(data_log, f\"data/{geometry}_video.mp4\", fps=6)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bbff1",
   "metadata": {},
   "source": [
    "## 3- Crop images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f271318",
   "metadata": {},
   "source": [
    "### 3-1 Select crop coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f972f",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "    \n",
    "By watching the video, we can see that the scattering signal always appears in the **same region** of the images.  \n",
    "To reduce the dataset size and focus the model on the relevant features, we will **crop each image** to keep only the region containing the signal.\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"app\">\n",
    "\n",
    "**visualize the first image** to decide the cropping boundaries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b8250d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_log[0,:, :],cmap='gray')\n",
    "plt.show();\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb81c7",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "\n",
    "**Visually inspect different slices** of the first image by trying various ranges for the `x` (columns) and `y` (rows) coordinates.  \n",
    "\n",
    "Crop image of index zero to obtain a square image of around 240x240 pixels\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ea051",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "# Define the crop ranges\n",
    "rows = slice(560, 800)  # y-range\n",
    "cols = slice(130, 370)  # x-range\n",
    "\n",
    "# Visualize the cropped region of the first image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_log[0, rows, cols], cmap='gray')\n",
    "ax.set_title(\"Cropped region of first image\");\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11473920",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "    \n",
    "Apply the crop to the data_log array (variable name : `data_crop`)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb9740",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "data_crop = data_log[:,rows, cols]\n",
    "print(\"Before Crop :\", data_log.shape)\n",
    "print(\"After Crop :\", data_crop.shape)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9009f",
   "metadata": {},
   "source": [
    "## 4- Pixels Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44a965",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "    \n",
    "In this section, we will **explore the distribution of pixel values** in our images with statistics and histograms.   \n",
    "\n",
    "This step is important because:  \n",
    "\n",
    "- It helps us **identify extreme values (outliers)** that may distort the training of a neural network.  \n",
    "- It indicates whether **pre-processing** (normalization, clipping, or outlier removal) might be necessary before training.  \n",
    "- It provides a clearer picture of the **intensity ranges** that the model will have to handle.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac37a8",
   "metadata": {},
   "source": [
    "### 4-1- Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4224b7",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "    \n",
    "Reuse the previously defined `print_image_stats` function to inspect our image of index 0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d62163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4e735",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "print_image_stats(data_crop, image_index=0)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2c46f",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "From the computed statistics we observe:\n",
    "\n",
    "- The **mean**  and **median**  are much closer to the **minimum** value  than to the **maximum** value.  \n",
    "- The **mean** is also noticeably higher than the **median**.  \n",
    "\n",
    "This suggests that the pixel value distribution is not balanced. We can verify this by plotting the histogram of the image.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c695d",
   "metadata": {},
   "source": [
    "### 4-2 Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff27f3d",
   "metadata": {},
   "source": [
    "##### 📝 Exercise: Plot Image Histogram  \n",
    "\n",
    "<div class=\"app\">\n",
    "\n",
    "Write a function `plot_image_histogram(data, image_index=0, bins=100)` that:  \n",
    "- takes a NumPy array `(n_images, height, width)`  \n",
    "- flattens the selected image’s pixels (`.ravel()`)  \n",
    "- plots their histogram with `matplotlib` (axis labels + title)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172d2fd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>🐢⏳ I'm stuck...</summary>\n",
    "\n",
    "**Goal:** Create a function that plots the **histogram of pixel values** of a selected image from a dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `plot_image_histogram`  \n",
    "- **Arguments:**\n",
    "  - `data` : a NumPy array of shape `(n_images, height, width)`  \n",
    "  - `image_index` : index of the image to plot (default: `0`)  \n",
    "  - `bins` : number of bins for the histogram (default: `100`)  \n",
    "- **Returns:**  \n",
    "  - Nothing, the function should display the histogram of pixel values.  \n",
    "- **Save the function in:** `visualization.py`\n",
    "\n",
    "**Steps:**\n",
    "1. Select the 2D image at `image_index` from `data`.  \n",
    "2. Flatten the image with `.ravel()` to get all pixel values in a 1D array.  \n",
    "3. Plot the histogram using `matplotlib.pyplot.hist`.  \n",
    "4. Add clear axis labels (“Pixel value” / “Number of pixels”) and a descriptive title indicating the image index.  \n",
    "5. Display the plot with `plt.show()`.\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```python\n",
    "# Plot the histogram of the first cropped image\n",
    "plot_image_histogram(data_crop, image_index=0, bins=100)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a1a36",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "def plot_image_histogram(data, image_index=0, bins=100):\n",
    "    \"\"\"\n",
    "    Plot the histogram of pixel values for a single 2D image within a 3D array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        3D array of images (N, H, W)\n",
    "    image_index : int, optional\n",
    "        Index of the image to plot (default: 0)\n",
    "    bins : int, optional\n",
    "        Number of bins for the histogram (default: 100)\n",
    "    \"\"\"\n",
    "    img = data[image_index, :, :]  # select 2D image\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.hist(img.ravel(), bins=bins, color='blue', alpha=0.7)\n",
    "    ax.set_xlabel('Pixel value')\n",
    "    ax.set_ylabel('Number of pixels')\n",
    "    ax.set_title(f'Histogram of pixels - image {image_index}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_image_histogram(data_crop) \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04dd17",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "We observe a few high pixel values in the image.\n",
    "\n",
    "Try now to **locate these outliers** by plotting red markers on pixels exceeding a chosen threshold in the first image.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bfbc4",
   "metadata": {},
   "source": [
    "### 4-3- Visualize outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6adc16",
   "metadata": {},
   "source": [
    "##### 📝 Exercise: Highlight Pixels Above Threshold  \n",
    "\n",
    "<div class=\"app\">\n",
    "    \n",
    "Write a function `show_image_with_pixels_over_threshold(image, threshold)` that:  \n",
    "- takes a 2D NumPy array `(height, width)`  \n",
    "- finds all pixels > `threshold`  \n",
    "- displays the image in grayscale and overlays these pixels in red  \n",
    "- prints the total number of highlighted pixels\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed20a33",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary>🐢⏳ I'm stuck...</summary>\n",
    "<div class=\"intro\">\n",
    "\n",
    "**Goal:** Create a function that displays a 2D image and **marks all pixels above a given threshold** in red.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `show_image_with_pixels_over_threshold`  \n",
    "- **Arguments:**\n",
    "  - `image` : a 2D NumPy array of shape `(height, width)`  \n",
    "  - `threshold` : pixel value threshold to highlight  \n",
    "- **Returns:**  \n",
    "  - Nothing, the function should display the image with marked pixels and print the number of pixels above the threshold.  \n",
    "- **Save the function in:** `visualization.py`\n",
    "\n",
    "**Steps:**\n",
    "1. Identify the coordinates of all pixels where the value is greater than `threshold`.  \n",
    "2. Plot the image using `matplotlib.pyplot.imshow` with a grayscale colormap.  \n",
    "3. Overlay the detected pixels as red markers using `plt.scatter`.  \n",
    "4. Add a title indicating the threshold value, hide axes, and include a legend.  \n",
    "5. Display the plot and print the total number of pixels above the threshold.  \n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```python\n",
    "# Highlight pixels above threshold 20 in the first cropped image\n",
    "show_image_with_pixels_over_threshold(data_crop[0], threshold=10)\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286ad4e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "def show_image_with_pixels_over_threshold(image, threshold=20):\n",
    "    \"\"\"\n",
    "    Display a 2D image with pixels above a threshold marked in red.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        2D image (height, width)\n",
    "    threshold : float\n",
    "        Threshold used to detect pixels\n",
    "    \"\"\"\n",
    "    # Find the coordinates of pixels > threshold\n",
    "    coords = np.where(image > threshold)  # (rows, cols)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.scatter(coords[1], coords[0], color='red', s=5, marker='x', label=f'>{threshold}')\n",
    "    plt.title(f'Pixels > {threshold}')\n",
    "    plt.axis('off')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Print the number of pixels above the threshold\n",
    "    print(f\"Number of pixels > {threshold}: {len(coords[0])}\")\n",
    "\n",
    "threshold = 10\n",
    "show_image_with_pixels_over_threshold(data_crop[0,:,:], threshold=threshold)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fbc3c",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "    \n",
    "We can now **localize the strong pixel values** in a single image.  \n",
    "However, analyzing just one image may not be representative of the dataset.  \n",
    "\n",
    "We will display **6 images** by passing **6 random indices** to your function to explore high-value pixels across multiple images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf5fce",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "\n",
    "To get a representative view of the dataset, we don’t want to display the first 6 images or just any sequential subset.  \n",
    "Instead, we **randomly select 6 image indices**. This ensures that we visualize a variety of images across the dataset and can inspect different features, like high-value pixels, across multiple samples.\n",
    "\n",
    "Create a list of 6 random numbers\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01754dd2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "import random\n",
    "# Randomly select 6 indices from the first dimension\n",
    "n_images = data_raw.shape[0]\n",
    "random_indices = random.sample(range(n_images), 6)\n",
    "print(random_indices)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a76f57",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "Check now on 6 random images with a plot function\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f320a",
   "metadata": {},
   "source": [
    "##### 📝 Exercise: Display 6 Random Images with Optional Threshold  \n",
    "\n",
    "<div class=\"app\">\n",
    "\n",
    "Write a function `plot_6images(data, indices, threshold=None, show_threshold=False, figsize=(10,6), cmap='gray')` that:  \n",
    "- takes a 3D NumPy array `(n_images, width, height)`  \n",
    "- displays 6 images specified by `indices` in a 2×3 grid  \n",
    "- optionally highlights pixels above `threshold` in red if `show_threshold=True`  \n",
    "- removes axes and adds titles for clarity\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f8dc9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>🐢⏳ I'm stuck...</summary>\n",
    "<div class=\"intro\">\n",
    "\n",
    "**Goal:** Create a function that displays **6 images** in a 2×3 grid. Optionally, mark the pixels above a given threshold in red.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `plot_6images`  \n",
    "- **Arguments:**\n",
    "  - `data` : 3D NumPy array of shape `(n_images, width, height)`  \n",
    "  - `indices` : list of 6 integer indices to display  \n",
    "  - `threshold` : float, optional, pixels above this value are highlighted \n",
    "  - `show_threshold` : bool, optional, whether to show pixels above threshold  \n",
    "  - `figsize` : tuple, optional, size of the figure \n",
    "  - `cmap` : str, optional, colormap to use  \n",
    "\n",
    "- **Returns:**  \n",
    "  - Nothing; displays a 2×3 grid of images, optionally highlighting pixels above the threshold.\n",
    "\n",
    "- **Steps:**\n",
    "1. Check that `indices` contains exactly 6 elements.  \n",
    "2. Loop over the 6 selected indices and plot each image in a subplot.  \n",
    "3. If `show_threshold` is True and `threshold` is set, overlay red markers on pixels exceeding the threshold.  \n",
    "4. Remove axes and set titles for readability.  \n",
    "5. Use `plt.tight_layout()` and `plt.show()` to display the figure cleanly.\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53031bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ccd61",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "def plot_6images(data, indices, threshold=None, show_threshold=True, figsize=(12, 6), cmap='gray'):\n",
    "    \"\"\"\n",
    "    Display images from a 3D array in a 2x3 grid.\n",
    "    Optionally highlight pixels above a given threshold in red.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        3D array of shape (n_images, width, height).\n",
    "    indices : list\n",
    "        List of 6 image indices to display.\n",
    "    threshold : float, optional\n",
    "        Threshold above which pixels are marked (None = no threshold).\n",
    "    show_threshold : bool, optional\n",
    "        True to show pixels above the threshold, False to ignore (default True).\n",
    "    figsize : tuple, optional\n",
    "        Size of the matplotlib figure (default (12, 6)).\n",
    "    cmap : str, optional\n",
    "        Colormap to use for displaying the images (default 'gray').\n",
    "    \"\"\"\n",
    "    if len(indices) != 6:\n",
    "        raise ValueError(\"La liste indices doit contenir exactement 6 éléments pour un affichage 2x3.\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for ax, idx in zip(axes, indices):\n",
    "        image = data[idx, :, :]\n",
    "        ax.imshow(image, cmap=cmap)\n",
    "\n",
    "        if show_threshold and threshold is not None:\n",
    "            coords = np.where(image > threshold)\n",
    "            ax.scatter(coords[1], coords[0], color='red', s=3, marker='.')\n",
    "\n",
    "        ax.set_title(f\"Image {idx}\", fontsize=12)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_6images(data_crop, random_indices, threshold=threshold, show_threshold=True)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad302e",
   "metadata": {},
   "source": [
    "### 4-4- Clip pixels values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36696f",
   "metadata": {},
   "source": [
    "<div class=\"introE\">\n",
    "\n",
    "We want an histogram with a good repartition on all the values. \n",
    "\n",
    "Most of the pixels above the chosen threshold are located near the **beamstop**, likely originating from the **direct beam**.\n",
    "\n",
    "In SAXS experiments, the meaningful scattering information is **not expected in this region**, so these extreme values can distort further analysis.\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"app\">\n",
    "\n",
    "To handle this, we will **cap the pixel values** at the threshold using `numpy.clip`, ensuring that all values above the threshold are set to the threshold value. This reduces the influence of outliers while keeping the rest of the image intact.\n",
    "\n",
    "Clip the data_crop array to max pixel value = threshold (variable name : `data_clip`)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4574b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136cbbf",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "data_clip = np.clip(data_crop, None, threshold) # min = None , max = threshold\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ce8da",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "    \n",
    "We will now **check the effect of clipping** by using the previously defined functions `print_image_stats` and `plot_image_histogram`.  \n",
    "\n",
    "Use previously define functions to read the statistics of pixels values of data_crop and data_clip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6523d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7a1f1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "print('Before Clip')\n",
    "print_image_stats(data_crop, image_index=0)\n",
    "print('After Clip')\n",
    "print_image_stats(data_clip, image_index=0)\n",
    "\n",
    "plot_image_histogram(data_clip)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65f804",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "    \n",
    "After clipping, the data distribution appears more **balanced**, meaning the histogram is more **centered** and the extreme values no longer dominate.  \n",
    "This makes the dataset easier to interpret and more suitable for training a neural network.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d620cc9",
   "metadata": {},
   "source": [
    "### 4-5- Normalize pixels values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd13e81",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "\n",
    "**Normalization** is the process of rescaling data to a standard range, usually between 0 and 1. For images, this means dividing pixel values by a reference value, such as the maximum value of the image or a fixed threshold.\n",
    "\n",
    "For **deep learning** normalization is benefic because:   \n",
    "\n",
    "- Neural networks perform better when inputs are on a **similar scale**.  \n",
    "- It helps **stabilize training** and speeds up **convergence**.  \n",
    "- Prevents **extreme values** (outliers) from dominating the learning process.  \n",
    "</div>\n",
    "<br>\n",
    "<div class=\"app\">\n",
    "\n",
    "In this dataset, we normalize each image individually to make the data suitable for training models that predict or classify based on pixel intensity patterns.\n",
    "\n",
    "Normalize the data_clip array (variable name : `data_norm`)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6fa3c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "# Compute the max of each image along (1,2) axes\n",
    "data_norm = data_clip / threshold\n",
    "\n",
    "print(data_clip.shape)\n",
    "for i in random_indices:\n",
    "    print_image_stats(data_norm, image_index=0)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b0993",
   "metadata": {},
   "source": [
    "## 5- Resize image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cd10d",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "    \n",
    "For CNNs, **resolution is not a key point** ; smaller images allow handling a **larger number of images** with the same memory footprint\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ddbd7",
   "metadata": {},
   "source": [
    "<div class=\"app\">\n",
    "\n",
    "Write a code to resize all images in `data_norm` to **128×128 pixels** using `skimage.transform.resize`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae27ad6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>🐢⏳ I'm stuck...</summary>\n",
    "<div class=\"intro\">\n",
    "    \n",
    "**Goal:** Reduce all images in `data_norm` to **128×128 pixels** using `skimage.transform`.  \n",
    "\n",
    "**Instructions:**  \n",
    "\n",
    "- Process the 3D array `data_norm` so that each image has shape `(128, 128)`.  \n",
    "- Verify the result by printing the shape of the new array.  \n",
    "\n",
    "**Hints:**  \n",
    "- Use `skimage.transform.resize`.  \n",
    "- Preserve the number of images.\n",
    "</div>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41199531",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "from skimage.transform import resize\n",
    "\n",
    "# data : (N, H, W)\n",
    "new_h, new_w = 128, 128\n",
    "data_resized = resize(\n",
    "    data_norm, \n",
    "    (data_norm.shape[0], new_h, new_w),  # même nombre d'images\n",
    "    order=1,                       # bilinear interpolation\n",
    "    preserve_range=True,            # garde les valeurs originales (pas normalisé)\n",
    "    anti_aliasing=True\n",
    ")\n",
    "print(\"Before resize: \",data_norm.shape)\n",
    "print(\"After Resize: \",data_resized.shape)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716dc83",
   "metadata": {},
   "source": [
    "## 5- Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84a8b2",
   "metadata": {},
   "source": [
    "<div class=\"intro\">\n",
    "\n",
    "We have now completed the **image dataset preparation** for one of the classes.  \n",
    "The same steps can be repeated for the other shapes (or automated with a loop), but we avoided this here to keep the notebook readable.\n",
    "\n",
    "**<u>Key Steps Applied</u>**:\n",
    "\n",
    "- **Focus on relevant regions:**  \n",
    "  - Crop images to keep only the region containing meaningful signal.  \n",
    "  - Remove outlier pixel values (extremely high pixels near the beamstop) to avoid biasing the model.\n",
    "- **Balance pixel values:**  \n",
    "  - Apply logarithmic transformations to better distribute intensity values.  \n",
    "  - Normalize pixel values (between 0 and 1, or using the maximum per image) to ensure consistency across the dataset.\n",
    "- **Resize images:**  \n",
    "  - Reduce image dimensions (here to 128×128) to allow faster processing and handling of larger datasets in deep learning.\n",
    "\n",
    "**<u>Notes</u>**. Although all images in this dataset come from the same source, in other datasets additional uniformization may be necessary:\n",
    "- Standardizing image sizes\n",
    "- Normalizing intensity ranges\n",
    "- Removing noise or artifacts\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"app\">\n",
    "\n",
    "In this dataset all image come from the same source but sometime operations of uniformization on size or pixel values are required. \n",
    "Finally, the processed images are **saved** in `geometry_data_preprocess.npy`, where `geometry` is one of `'circle'`, `'square'`, or `'triangle'`.  \n",
    "\n",
    "Save datas in a numpy file\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a1b6d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Solution</summary>\n",
    "\n",
    "```python\n",
    "save_path = f\"data/{geometry}_data_preprocess.npy\"\n",
    "np.save(save_path, data_resized)\n",
    "print(f\"File saved in {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c963d",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "All the data (source and result of executions) are accessible at [this link](https://drive.google.com/drive/folders/1W7PkhKiEJ5tiaiid51o-xw0BiJCfb2AZ?usp=sharing)\n",
    "\n",
    "Open now the [next notebook](dataset_creation_workshop.ipynb). We will use these three files to assemble the full dataset.   \n",
    "\n",
    "[Corrected version of this notebook](image_processing_correction.ipynb)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f941cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vID.end(cwd0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
