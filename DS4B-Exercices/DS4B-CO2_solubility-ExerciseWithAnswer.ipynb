{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10024ca9-7e94-4f5c-a982-b4537b919d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: bold;\n",
       "}\n",
       "body, exercice {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: 200;\n",
       "}\n",
       "h1 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 30px ;\n",
       "  color: white;\n",
       "  background: #b11d01;\n",
       "  text-align: center;\n",
       "}\n",
       "h2 {\n",
       "  border: 3px solid #333;\n",
       "  padding: 18px ;\n",
       "  color: #b11d01;\n",
       "  background: #ffffff;\n",
       "  text-align: center;\n",
       "}\n",
       "h3 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 12px ;\n",
       "  color: #000000;\n",
       "  background: #c1c1c1;\n",
       "  text-align: left;\n",
       "}\n",
       "h4 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #d9fffc;\n",
       "  text-align: left;\n",
       "}\n",
       "h5 {\n",
       "  border: 1px solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #ffffff;\n",
       "  text-align: left;\n",
       "}\n",
       ".rq {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       ".intro {    \n",
       "    background-color: #f1f1f1;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       ".exold {    \n",
       "    background-color: #b2dbea80;\n",
       "    border-color: #0055ff;\n",
       "    border-left: 10px solid #0055ff;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       ".ex {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    font-weight: 200;\n",
       "    position:relative;\n",
       "    }\n",
       ".ex::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Exercice\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "    }\n",
       ".app {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    font-weight: 200;\n",
       "    position:relative;\n",
       "    }\n",
       ".app::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Application\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Start at:** Tuesday 28 March 2023, 14:53:03  \n",
       "**Hostname:** insa-12842 (Linux)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"../config/svg/PytChemBanner.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cwd0 = '../config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID_Eng as vID\n",
    "from visualID_Eng import color\n",
    "vID.init(cwd0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e4b9b",
   "metadata": {},
   "source": [
    "# Prediction by an artificial neural network of the solubility of CO<sub>2</sub> in ionic liquids\n",
    "\n",
    "<div class=\"rq\">\n",
    "    \n",
    "<b>Reference</b>: \n",
    "Z. Song, H. Shi, X. Zhang & T. Zhou (**2020**), Prediction of CO<sub>2</sub> solubility in ionic liquids using machine learning methods, [<i>Chem. Eng. Sci.</i> <b>223</b>: 115752](https://www.doi.org/10.1016/j.ces.2020.115752) \n",
    "<br>\n",
    "<p style=\"text-align: center\"><img width=\"650px\" src=\"../DS4B-CO2-images/AbstractANNCO2-SongEtal.png\" style=\"margin-left:auto; margin-right:auto\" id=\"img_AbstractSong\"></p>\n",
    "<br>\n",
    "The main results are graphically reported below.\n",
    "<br>\n",
    "<p style=\"text-align: center\"><img width=\"900px\" src=\"../DS4B-CO2-images/ANNCO2-SongEtal-Results.png\" style=\"margin-left:auto; margin-right:auto\" id=\"img_ResultsSong\"></p>\n",
    "<br>\n",
    "Yet, it seems sthat no standardization process of the data has been applied. \n",
    "    \n",
    "<span style=\"color:red\">Moreover, a spurious separation of the data between training and test sets has been applied: \"<i>Instead of performing random selection, we employ a hybrid artificial-random strategy to decompose the dataset. Specifically, the data points consisting of the least frequently used groups are equally divided into five folders\"</i></span> \n",
    "<br><br>\n",
    "<b>It raises doubts about the stability of the algorithm developped in this paper (*unless the authors forgot to mention that data were standardized*).</b>\n",
    "<br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84860c4-3fcf-45f5-80a3-607ead68da80",
   "metadata": {},
   "source": [
    "<div class=\"warn\">\n",
    "<span style=\"font-weight:bold\">The goal of this exercise is to apply the <i>K</i>-fold cross-validation the ANN part of this article, <i>i.e.</i> without standardized data. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af39c092-f4b7-460b-b698-32e0f2c55461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 14:53:05.438156: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 14:53:05.489211: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os,sys\n",
    "from IPython.display import display\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   OFF = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a89d-fb12-4ba1-8382-1609a0c4f848",
   "metadata": {},
   "source": [
    "<a id=\"data-read\"></a>\n",
    "## **1.** Database reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d2251b-1f22-42f5-b930-e6032fe55170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IL</th>\n",
       "      <th>cation</th>\n",
       "      <th>anion</th>\n",
       "      <th>x_CO2</th>\n",
       "      <th>T (K)</th>\n",
       "      <th>P (bar)</th>\n",
       "      <th>[CH3]</th>\n",
       "      <th>[CH2]</th>\n",
       "      <th>[CH]</th>\n",
       "      <th>[OCH2]</th>\n",
       "      <th>...</th>\n",
       "      <th>[MeSO3]</th>\n",
       "      <th>[TfO]</th>\n",
       "      <th>[NfO]</th>\n",
       "      <th>[TDfO]</th>\n",
       "      <th>[TOS]</th>\n",
       "      <th>[C12PhSO3]</th>\n",
       "      <th>[DMPO4]</th>\n",
       "      <th>[DEPO4]</th>\n",
       "      <th>[DBPO4]</th>\n",
       "      <th>[methide]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BMIM][BF4]</td>\n",
       "      <td>[BMIM]</td>\n",
       "      <td>[BF4]</td>\n",
       "      <td>0.610</td>\n",
       "      <td>363.15</td>\n",
       "      <td>246.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BMIM][BF4]</td>\n",
       "      <td>[BMIM]</td>\n",
       "      <td>[BF4]</td>\n",
       "      <td>0.500</td>\n",
       "      <td>383.15</td>\n",
       "      <td>235.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[BMIM][BF4]</td>\n",
       "      <td>[BMIM]</td>\n",
       "      <td>[BF4]</td>\n",
       "      <td>0.610</td>\n",
       "      <td>353.15</td>\n",
       "      <td>223.30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[BMIM][BF4]</td>\n",
       "      <td>[BMIM]</td>\n",
       "      <td>[BF4]</td>\n",
       "      <td>0.500</td>\n",
       "      <td>373.15</td>\n",
       "      <td>198.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[BMIM][BF4]</td>\n",
       "      <td>[BMIM]</td>\n",
       "      <td>[BF4]</td>\n",
       "      <td>0.610</td>\n",
       "      <td>343.15</td>\n",
       "      <td>188.50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>[HMIM][Tf2N]</td>\n",
       "      <td>[HMIM]</td>\n",
       "      <td>[Tf2N]</td>\n",
       "      <td>0.592</td>\n",
       "      <td>298.15</td>\n",
       "      <td>35.86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10112</th>\n",
       "      <td>[HMIM][Tf2N]</td>\n",
       "      <td>[HMIM]</td>\n",
       "      <td>[Tf2N]</td>\n",
       "      <td>0.239</td>\n",
       "      <td>343.15</td>\n",
       "      <td>27.54</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>[HMIM][Tf2N]</td>\n",
       "      <td>[HMIM]</td>\n",
       "      <td>[Tf2N]</td>\n",
       "      <td>0.396</td>\n",
       "      <td>298.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10114</th>\n",
       "      <td>[HMIM][Tf2N]</td>\n",
       "      <td>[HMIM]</td>\n",
       "      <td>[Tf2N]</td>\n",
       "      <td>0.140</td>\n",
       "      <td>343.15</td>\n",
       "      <td>17.93</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115</th>\n",
       "      <td>[HMIM][Tf2N]</td>\n",
       "      <td>[HMIM]</td>\n",
       "      <td>[Tf2N]</td>\n",
       "      <td>0.139</td>\n",
       "      <td>323.15</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10116 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IL  cation   anion  x_CO2   T (K)  P (bar)  [CH3]  [CH2]  \\\n",
       "0       [BMIM][BF4]  [BMIM]   [BF4]  0.610  363.15   246.00      1      3   \n",
       "1       [BMIM][BF4]  [BMIM]   [BF4]  0.500  383.15   235.00      1      3   \n",
       "2       [BMIM][BF4]  [BMIM]   [BF4]  0.610  353.15   223.30      1      3   \n",
       "3       [BMIM][BF4]  [BMIM]   [BF4]  0.500  373.15   198.00      1      3   \n",
       "4       [BMIM][BF4]  [BMIM]   [BF4]  0.610  343.15   188.50      1      3   \n",
       "...             ...     ...     ...    ...     ...      ...    ...    ...   \n",
       "10111  [HMIM][Tf2N]  [HMIM]  [Tf2N]  0.592  298.15    35.86      1      5   \n",
       "10112  [HMIM][Tf2N]  [HMIM]  [Tf2N]  0.239  343.15    27.54      1      5   \n",
       "10113  [HMIM][Tf2N]  [HMIM]  [Tf2N]  0.396  298.15    20.15      1      5   \n",
       "10114  [HMIM][Tf2N]  [HMIM]  [Tf2N]  0.140  343.15    17.93      1      5   \n",
       "10115  [HMIM][Tf2N]  [HMIM]  [Tf2N]  0.139  323.15     8.00      1      5   \n",
       "\n",
       "       [CH]  [OCH2]  ...  [MeSO3]  [TfO]  [NfO]  [TDfO]  [TOS]  [C12PhSO3]  \\\n",
       "0         0       0  ...        0      0      0       0      0           0   \n",
       "1         0       0  ...        0      0      0       0      0           0   \n",
       "2         0       0  ...        0      0      0       0      0           0   \n",
       "3         0       0  ...        0      0      0       0      0           0   \n",
       "4         0       0  ...        0      0      0       0      0           0   \n",
       "...     ...     ...  ...      ...    ...    ...     ...    ...         ...   \n",
       "10111     0       0  ...        0      0      0       0      0           0   \n",
       "10112     0       0  ...        0      0      0       0      0           0   \n",
       "10113     0       0  ...        0      0      0       0      0           0   \n",
       "10114     0       0  ...        0      0      0       0      0           0   \n",
       "10115     0       0  ...        0      0      0       0      0           0   \n",
       "\n",
       "       [DMPO4]  [DEPO4]  [DBPO4]  [methide]  \n",
       "0            0        0        0          0  \n",
       "1            0        0        0          0  \n",
       "2            0        0        0          0  \n",
       "3            0        0        0          0  \n",
       "4            0        0        0          0  \n",
       "...        ...      ...      ...        ...  \n",
       "10111        0        0        0          0  \n",
       "10112        0        0        0          0  \n",
       "10113        0        0        0          0  \n",
       "10114        0        0        0          0  \n",
       "10115        0        0        0          0  \n",
       "\n",
       "[10116 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_81b2f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81b2f_level0_col0\" class=\"col_heading level0 col0\" >x_CO2</th>\n",
       "      <th id=\"T_81b2f_level0_col1\" class=\"col_heading level0 col1\" >T (K)</th>\n",
       "      <th id=\"T_81b2f_level0_col2\" class=\"col_heading level0 col2\" >P (bar)</th>\n",
       "      <th id=\"T_81b2f_level0_col3\" class=\"col_heading level0 col3\" >[CH3]</th>\n",
       "      <th id=\"T_81b2f_level0_col4\" class=\"col_heading level0 col4\" >[CH2]</th>\n",
       "      <th id=\"T_81b2f_level0_col5\" class=\"col_heading level0 col5\" >[CH]</th>\n",
       "      <th id=\"T_81b2f_level0_col6\" class=\"col_heading level0 col6\" >[OCH2]</th>\n",
       "      <th id=\"T_81b2f_level0_col7\" class=\"col_heading level0 col7\" >[OCH3]</th>\n",
       "      <th id=\"T_81b2f_level0_col8\" class=\"col_heading level0 col8\" >[CF2]</th>\n",
       "      <th id=\"T_81b2f_level0_col9\" class=\"col_heading level0 col9\" >[CF3]</th>\n",
       "      <th id=\"T_81b2f_level0_col10\" class=\"col_heading level0 col10\" >[OH]</th>\n",
       "      <th id=\"T_81b2f_level0_col11\" class=\"col_heading level0 col11\" >CH=CH</th>\n",
       "      <th id=\"T_81b2f_level0_col12\" class=\"col_heading level0 col12\" >CH=CH2</th>\n",
       "      <th id=\"T_81b2f_level0_col13\" class=\"col_heading level0 col13\" >[Im13]</th>\n",
       "      <th id=\"T_81b2f_level0_col14\" class=\"col_heading level0 col14\" >[MIm]</th>\n",
       "      <th id=\"T_81b2f_level0_col15\" class=\"col_heading level0 col15\" >[MMIM]</th>\n",
       "      <th id=\"T_81b2f_level0_col16\" class=\"col_heading level0 col16\" >[Py]</th>\n",
       "      <th id=\"T_81b2f_level0_col17\" class=\"col_heading level0 col17\" >[MPy]</th>\n",
       "      <th id=\"T_81b2f_level0_col18\" class=\"col_heading level0 col18\" >[MPyrro]</th>\n",
       "      <th id=\"T_81b2f_level0_col19\" class=\"col_heading level0 col19\" >[MPip]</th>\n",
       "      <th id=\"T_81b2f_level0_col20\" class=\"col_heading level0 col20\" >[NH3]</th>\n",
       "      <th id=\"T_81b2f_level0_col21\" class=\"col_heading level0 col21\" >[NH2]</th>\n",
       "      <th id=\"T_81b2f_level0_col22\" class=\"col_heading level0 col22\" >[NH]</th>\n",
       "      <th id=\"T_81b2f_level0_col23\" class=\"col_heading level0 col23\" >[N]</th>\n",
       "      <th id=\"T_81b2f_level0_col24\" class=\"col_heading level0 col24\" >[P]</th>\n",
       "      <th id=\"T_81b2f_level0_col25\" class=\"col_heading level0 col25\" >[S]</th>\n",
       "      <th id=\"T_81b2f_level0_col26\" class=\"col_heading level0 col26\" >[BF4]</th>\n",
       "      <th id=\"T_81b2f_level0_col27\" class=\"col_heading level0 col27\" >[Cl]</th>\n",
       "      <th id=\"T_81b2f_level0_col28\" class=\"col_heading level0 col28\" >[DCA]</th>\n",
       "      <th id=\"T_81b2f_level0_col29\" class=\"col_heading level0 col29\" >[NO3]</th>\n",
       "      <th id=\"T_81b2f_level0_col30\" class=\"col_heading level0 col30\" >[PF6]</th>\n",
       "      <th id=\"T_81b2f_level0_col31\" class=\"col_heading level0 col31\" >[SCN]</th>\n",
       "      <th id=\"T_81b2f_level0_col32\" class=\"col_heading level0 col32\" >[TCB]</th>\n",
       "      <th id=\"T_81b2f_level0_col33\" class=\"col_heading level0 col33\" >[C(CN)3]</th>\n",
       "      <th id=\"T_81b2f_level0_col34\" class=\"col_heading level0 col34\" >[HSO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col35\" class=\"col_heading level0 col35\" >[FSA]</th>\n",
       "      <th id=\"T_81b2f_level0_col36\" class=\"col_heading level0 col36\" >[Tf2N]</th>\n",
       "      <th id=\"T_81b2f_level0_col37\" class=\"col_heading level0 col37\" >[BETA]</th>\n",
       "      <th id=\"T_81b2f_level0_col38\" class=\"col_heading level0 col38\" >[FOR]</th>\n",
       "      <th id=\"T_81b2f_level0_col39\" class=\"col_heading level0 col39\" >[TFA]</th>\n",
       "      <th id=\"T_81b2f_level0_col40\" class=\"col_heading level0 col40\" >[C3F7CO2]</th>\n",
       "      <th id=\"T_81b2f_level0_col41\" class=\"col_heading level0 col41\" >[MeSO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col42\" class=\"col_heading level0 col42\" >[EtSO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col43\" class=\"col_heading level0 col43\" >[MDEGSO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col44\" class=\"col_heading level0 col44\" >[MeSO3]</th>\n",
       "      <th id=\"T_81b2f_level0_col45\" class=\"col_heading level0 col45\" >[TfO]</th>\n",
       "      <th id=\"T_81b2f_level0_col46\" class=\"col_heading level0 col46\" >[NfO]</th>\n",
       "      <th id=\"T_81b2f_level0_col47\" class=\"col_heading level0 col47\" >[TDfO]</th>\n",
       "      <th id=\"T_81b2f_level0_col48\" class=\"col_heading level0 col48\" >[TOS]</th>\n",
       "      <th id=\"T_81b2f_level0_col49\" class=\"col_heading level0 col49\" >[C12PhSO3]</th>\n",
       "      <th id=\"T_81b2f_level0_col50\" class=\"col_heading level0 col50\" >[DMPO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col51\" class=\"col_heading level0 col51\" >[DEPO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col52\" class=\"col_heading level0 col52\" >[DBPO4]</th>\n",
       "      <th id=\"T_81b2f_level0_col53\" class=\"col_heading level0 col53\" >[methide]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_81b2f_row0_col0\" class=\"data row0 col0\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col1\" class=\"data row0 col1\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col2\" class=\"data row0 col2\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col3\" class=\"data row0 col3\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col4\" class=\"data row0 col4\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col5\" class=\"data row0 col5\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col6\" class=\"data row0 col6\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col7\" class=\"data row0 col7\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col8\" class=\"data row0 col8\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col9\" class=\"data row0 col9\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col10\" class=\"data row0 col10\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col11\" class=\"data row0 col11\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col12\" class=\"data row0 col12\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col13\" class=\"data row0 col13\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col14\" class=\"data row0 col14\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col15\" class=\"data row0 col15\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col16\" class=\"data row0 col16\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col17\" class=\"data row0 col17\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col18\" class=\"data row0 col18\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col19\" class=\"data row0 col19\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col20\" class=\"data row0 col20\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col21\" class=\"data row0 col21\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col22\" class=\"data row0 col22\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col23\" class=\"data row0 col23\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col24\" class=\"data row0 col24\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col25\" class=\"data row0 col25\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col26\" class=\"data row0 col26\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col27\" class=\"data row0 col27\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col28\" class=\"data row0 col28\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col29\" class=\"data row0 col29\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col30\" class=\"data row0 col30\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col31\" class=\"data row0 col31\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col32\" class=\"data row0 col32\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col33\" class=\"data row0 col33\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col34\" class=\"data row0 col34\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col35\" class=\"data row0 col35\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col36\" class=\"data row0 col36\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col37\" class=\"data row0 col37\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col38\" class=\"data row0 col38\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col39\" class=\"data row0 col39\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col40\" class=\"data row0 col40\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col41\" class=\"data row0 col41\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col42\" class=\"data row0 col42\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col43\" class=\"data row0 col43\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col44\" class=\"data row0 col44\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col45\" class=\"data row0 col45\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col46\" class=\"data row0 col46\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col47\" class=\"data row0 col47\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col48\" class=\"data row0 col48\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col49\" class=\"data row0 col49\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col50\" class=\"data row0 col50\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col51\" class=\"data row0 col51\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col52\" class=\"data row0 col52\" >10116.00</td>\n",
       "      <td id=\"T_81b2f_row0_col53\" class=\"data row0 col53\" >10116.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_81b2f_row1_col0\" class=\"data row1 col0\" >0.33</td>\n",
       "      <td id=\"T_81b2f_row1_col1\" class=\"data row1 col1\" >325.27</td>\n",
       "      <td id=\"T_81b2f_row1_col2\" class=\"data row1 col2\" >54.21</td>\n",
       "      <td id=\"T_81b2f_row1_col3\" class=\"data row1 col3\" >1.18</td>\n",
       "      <td id=\"T_81b2f_row1_col4\" class=\"data row1 col4\" >4.72</td>\n",
       "      <td id=\"T_81b2f_row1_col5\" class=\"data row1 col5\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col6\" class=\"data row1 col6\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col7\" class=\"data row1 col7\" >0.04</td>\n",
       "      <td id=\"T_81b2f_row1_col8\" class=\"data row1 col8\" >0.04</td>\n",
       "      <td id=\"T_81b2f_row1_col9\" class=\"data row1 col9\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col10\" class=\"data row1 col10\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row1_col11\" class=\"data row1 col11\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col12\" class=\"data row1 col12\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col13\" class=\"data row1 col13\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col14\" class=\"data row1 col14\" >0.77</td>\n",
       "      <td id=\"T_81b2f_row1_col15\" class=\"data row1 col15\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col16\" class=\"data row1 col16\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col17\" class=\"data row1 col17\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col18\" class=\"data row1 col18\" >0.09</td>\n",
       "      <td id=\"T_81b2f_row1_col19\" class=\"data row1 col19\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col20\" class=\"data row1 col20\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col21\" class=\"data row1 col21\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col22\" class=\"data row1 col22\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col23\" class=\"data row1 col23\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col24\" class=\"data row1 col24\" >0.05</td>\n",
       "      <td id=\"T_81b2f_row1_col25\" class=\"data row1 col25\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col26\" class=\"data row1 col26\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row1_col27\" class=\"data row1 col27\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col28\" class=\"data row1 col28\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col29\" class=\"data row1 col29\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col30\" class=\"data row1 col30\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row1_col31\" class=\"data row1 col31\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col32\" class=\"data row1 col32\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col33\" class=\"data row1 col33\" >0.07</td>\n",
       "      <td id=\"T_81b2f_row1_col34\" class=\"data row1 col34\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col35\" class=\"data row1 col35\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col36\" class=\"data row1 col36\" >0.43</td>\n",
       "      <td id=\"T_81b2f_row1_col37\" class=\"data row1 col37\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col38\" class=\"data row1 col38\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col39\" class=\"data row1 col39\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col40\" class=\"data row1 col40\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col41\" class=\"data row1 col41\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col42\" class=\"data row1 col42\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col43\" class=\"data row1 col43\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col44\" class=\"data row1 col44\" >0.02</td>\n",
       "      <td id=\"T_81b2f_row1_col45\" class=\"data row1 col45\" >0.05</td>\n",
       "      <td id=\"T_81b2f_row1_col46\" class=\"data row1 col46\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col47\" class=\"data row1 col47\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col48\" class=\"data row1 col48\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col49\" class=\"data row1 col49\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col50\" class=\"data row1 col50\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col51\" class=\"data row1 col51\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row1_col52\" class=\"data row1 col52\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row1_col53\" class=\"data row1 col53\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_81b2f_row2_col0\" class=\"data row2 col0\" >0.24</td>\n",
       "      <td id=\"T_81b2f_row2_col1\" class=\"data row2 col1\" >25.24</td>\n",
       "      <td id=\"T_81b2f_row2_col2\" class=\"data row2 col2\" >76.66</td>\n",
       "      <td id=\"T_81b2f_row2_col3\" class=\"data row2 col3\" >0.96</td>\n",
       "      <td id=\"T_81b2f_row2_col4\" class=\"data row2 col4\" >5.48</td>\n",
       "      <td id=\"T_81b2f_row2_col5\" class=\"data row2 col5\" >0.25</td>\n",
       "      <td id=\"T_81b2f_row2_col6\" class=\"data row2 col6\" >0.16</td>\n",
       "      <td id=\"T_81b2f_row2_col7\" class=\"data row2 col7\" >0.20</td>\n",
       "      <td id=\"T_81b2f_row2_col8\" class=\"data row2 col8\" >0.39</td>\n",
       "      <td id=\"T_81b2f_row2_col9\" class=\"data row2 col9\" >0.10</td>\n",
       "      <td id=\"T_81b2f_row2_col10\" class=\"data row2 col10\" >0.28</td>\n",
       "      <td id=\"T_81b2f_row2_col11\" class=\"data row2 col11\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row2_col12\" class=\"data row2 col12\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row2_col13\" class=\"data row2 col13\" >0.10</td>\n",
       "      <td id=\"T_81b2f_row2_col14\" class=\"data row2 col14\" >0.42</td>\n",
       "      <td id=\"T_81b2f_row2_col15\" class=\"data row2 col15\" >0.08</td>\n",
       "      <td id=\"T_81b2f_row2_col16\" class=\"data row2 col16\" >0.07</td>\n",
       "      <td id=\"T_81b2f_row2_col17\" class=\"data row2 col17\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row2_col18\" class=\"data row2 col18\" >0.29</td>\n",
       "      <td id=\"T_81b2f_row2_col19\" class=\"data row2 col19\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row2_col20\" class=\"data row2 col20\" >0.07</td>\n",
       "      <td id=\"T_81b2f_row2_col21\" class=\"data row2 col21\" >0.09</td>\n",
       "      <td id=\"T_81b2f_row2_col22\" class=\"data row2 col22\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row2_col23\" class=\"data row2 col23\" >0.16</td>\n",
       "      <td id=\"T_81b2f_row2_col24\" class=\"data row2 col24\" >0.23</td>\n",
       "      <td id=\"T_81b2f_row2_col25\" class=\"data row2 col25\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row2_col26\" class=\"data row2 col26\" >0.31</td>\n",
       "      <td id=\"T_81b2f_row2_col27\" class=\"data row2 col27\" >0.12</td>\n",
       "      <td id=\"T_81b2f_row2_col28\" class=\"data row2 col28\" >0.15</td>\n",
       "      <td id=\"T_81b2f_row2_col29\" class=\"data row2 col29\" >0.12</td>\n",
       "      <td id=\"T_81b2f_row2_col30\" class=\"data row2 col30\" >0.31</td>\n",
       "      <td id=\"T_81b2f_row2_col31\" class=\"data row2 col31\" >0.14</td>\n",
       "      <td id=\"T_81b2f_row2_col32\" class=\"data row2 col32\" >0.08</td>\n",
       "      <td id=\"T_81b2f_row2_col33\" class=\"data row2 col33\" >0.26</td>\n",
       "      <td id=\"T_81b2f_row2_col34\" class=\"data row2 col34\" >0.04</td>\n",
       "      <td id=\"T_81b2f_row2_col35\" class=\"data row2 col35\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row2_col36\" class=\"data row2 col36\" >0.49</td>\n",
       "      <td id=\"T_81b2f_row2_col37\" class=\"data row2 col37\" >0.03</td>\n",
       "      <td id=\"T_81b2f_row2_col38\" class=\"data row2 col38\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row2_col39\" class=\"data row2 col39\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row2_col40\" class=\"data row2 col40\" >0.05</td>\n",
       "      <td id=\"T_81b2f_row2_col41\" class=\"data row2 col41\" >0.13</td>\n",
       "      <td id=\"T_81b2f_row2_col42\" class=\"data row2 col42\" >0.11</td>\n",
       "      <td id=\"T_81b2f_row2_col43\" class=\"data row2 col43\" >0.10</td>\n",
       "      <td id=\"T_81b2f_row2_col44\" class=\"data row2 col44\" >0.15</td>\n",
       "      <td id=\"T_81b2f_row2_col45\" class=\"data row2 col45\" >0.23</td>\n",
       "      <td id=\"T_81b2f_row2_col46\" class=\"data row2 col46\" >0.09</td>\n",
       "      <td id=\"T_81b2f_row2_col47\" class=\"data row2 col47\" >0.08</td>\n",
       "      <td id=\"T_81b2f_row2_col48\" class=\"data row2 col48\" >0.06</td>\n",
       "      <td id=\"T_81b2f_row2_col49\" class=\"data row2 col49\" >0.10</td>\n",
       "      <td id=\"T_81b2f_row2_col50\" class=\"data row2 col50\" >0.03</td>\n",
       "      <td id=\"T_81b2f_row2_col51\" class=\"data row2 col51\" >0.07</td>\n",
       "      <td id=\"T_81b2f_row2_col52\" class=\"data row2 col52\" >0.04</td>\n",
       "      <td id=\"T_81b2f_row2_col53\" class=\"data row2 col53\" >0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_81b2f_row3_col0\" class=\"data row3 col0\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col1\" class=\"data row3 col1\" >243.20</td>\n",
       "      <td id=\"T_81b2f_row3_col2\" class=\"data row3 col2\" >0.01</td>\n",
       "      <td id=\"T_81b2f_row3_col3\" class=\"data row3 col3\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col4\" class=\"data row3 col4\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col5\" class=\"data row3 col5\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col6\" class=\"data row3 col6\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col7\" class=\"data row3 col7\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col8\" class=\"data row3 col8\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col9\" class=\"data row3 col9\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col10\" class=\"data row3 col10\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col11\" class=\"data row3 col11\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col12\" class=\"data row3 col12\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col13\" class=\"data row3 col13\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col14\" class=\"data row3 col14\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col15\" class=\"data row3 col15\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col16\" class=\"data row3 col16\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col17\" class=\"data row3 col17\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col18\" class=\"data row3 col18\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col19\" class=\"data row3 col19\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col20\" class=\"data row3 col20\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col21\" class=\"data row3 col21\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col22\" class=\"data row3 col22\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col23\" class=\"data row3 col23\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col24\" class=\"data row3 col24\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col25\" class=\"data row3 col25\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col26\" class=\"data row3 col26\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col27\" class=\"data row3 col27\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col28\" class=\"data row3 col28\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col29\" class=\"data row3 col29\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col30\" class=\"data row3 col30\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col31\" class=\"data row3 col31\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col32\" class=\"data row3 col32\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col33\" class=\"data row3 col33\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col34\" class=\"data row3 col34\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col35\" class=\"data row3 col35\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col36\" class=\"data row3 col36\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col37\" class=\"data row3 col37\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col38\" class=\"data row3 col38\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col39\" class=\"data row3 col39\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col40\" class=\"data row3 col40\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col41\" class=\"data row3 col41\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col42\" class=\"data row3 col42\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col43\" class=\"data row3 col43\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col44\" class=\"data row3 col44\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col45\" class=\"data row3 col45\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col46\" class=\"data row3 col46\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col47\" class=\"data row3 col47\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col48\" class=\"data row3 col48\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col49\" class=\"data row3 col49\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col50\" class=\"data row3 col50\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col51\" class=\"data row3 col51\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col52\" class=\"data row3 col52\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row3_col53\" class=\"data row3 col53\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_81b2f_row4_col0\" class=\"data row4 col0\" >0.14</td>\n",
       "      <td id=\"T_81b2f_row4_col1\" class=\"data row4 col1\" >308.15</td>\n",
       "      <td id=\"T_81b2f_row4_col2\" class=\"data row4 col2\" >10.00</td>\n",
       "      <td id=\"T_81b2f_row4_col3\" class=\"data row4 col3\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row4_col4\" class=\"data row4 col4\" >3.00</td>\n",
       "      <td id=\"T_81b2f_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col11\" class=\"data row4 col11\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col12\" class=\"data row4 col12\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col13\" class=\"data row4 col13\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col14\" class=\"data row4 col14\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row4_col15\" class=\"data row4 col15\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col16\" class=\"data row4 col16\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col17\" class=\"data row4 col17\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col18\" class=\"data row4 col18\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col19\" class=\"data row4 col19\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col20\" class=\"data row4 col20\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col21\" class=\"data row4 col21\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col22\" class=\"data row4 col22\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col23\" class=\"data row4 col23\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col24\" class=\"data row4 col24\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col25\" class=\"data row4 col25\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col26\" class=\"data row4 col26\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col27\" class=\"data row4 col27\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col28\" class=\"data row4 col28\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col29\" class=\"data row4 col29\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col30\" class=\"data row4 col30\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col31\" class=\"data row4 col31\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col32\" class=\"data row4 col32\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col33\" class=\"data row4 col33\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col34\" class=\"data row4 col34\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col35\" class=\"data row4 col35\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col36\" class=\"data row4 col36\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col37\" class=\"data row4 col37\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col38\" class=\"data row4 col38\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col39\" class=\"data row4 col39\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col40\" class=\"data row4 col40\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col41\" class=\"data row4 col41\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col42\" class=\"data row4 col42\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col43\" class=\"data row4 col43\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col44\" class=\"data row4 col44\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col45\" class=\"data row4 col45\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col46\" class=\"data row4 col46\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col47\" class=\"data row4 col47\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col48\" class=\"data row4 col48\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col49\" class=\"data row4 col49\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col50\" class=\"data row4 col50\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col51\" class=\"data row4 col51\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col52\" class=\"data row4 col52\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row4_col53\" class=\"data row4 col53\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_81b2f_row5_col0\" class=\"data row5 col0\" >0.30</td>\n",
       "      <td id=\"T_81b2f_row5_col1\" class=\"data row5 col1\" >323.15</td>\n",
       "      <td id=\"T_81b2f_row5_col2\" class=\"data row5 col2\" >26.80</td>\n",
       "      <td id=\"T_81b2f_row5_col3\" class=\"data row5 col3\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row5_col4\" class=\"data row5 col4\" >3.00</td>\n",
       "      <td id=\"T_81b2f_row5_col5\" class=\"data row5 col5\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col6\" class=\"data row5 col6\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col7\" class=\"data row5 col7\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col8\" class=\"data row5 col8\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col9\" class=\"data row5 col9\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col10\" class=\"data row5 col10\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col11\" class=\"data row5 col11\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col12\" class=\"data row5 col12\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col13\" class=\"data row5 col13\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col14\" class=\"data row5 col14\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row5_col15\" class=\"data row5 col15\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col16\" class=\"data row5 col16\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col17\" class=\"data row5 col17\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col18\" class=\"data row5 col18\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col19\" class=\"data row5 col19\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col20\" class=\"data row5 col20\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col21\" class=\"data row5 col21\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col22\" class=\"data row5 col22\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col23\" class=\"data row5 col23\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col24\" class=\"data row5 col24\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col25\" class=\"data row5 col25\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col26\" class=\"data row5 col26\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col27\" class=\"data row5 col27\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col28\" class=\"data row5 col28\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col29\" class=\"data row5 col29\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col30\" class=\"data row5 col30\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col31\" class=\"data row5 col31\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col32\" class=\"data row5 col32\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col33\" class=\"data row5 col33\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col34\" class=\"data row5 col34\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col35\" class=\"data row5 col35\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col36\" class=\"data row5 col36\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col37\" class=\"data row5 col37\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col38\" class=\"data row5 col38\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col39\" class=\"data row5 col39\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col40\" class=\"data row5 col40\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col41\" class=\"data row5 col41\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col42\" class=\"data row5 col42\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col43\" class=\"data row5 col43\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col44\" class=\"data row5 col44\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col45\" class=\"data row5 col45\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col46\" class=\"data row5 col46\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col47\" class=\"data row5 col47\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col48\" class=\"data row5 col48\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col49\" class=\"data row5 col49\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col50\" class=\"data row5 col50\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col51\" class=\"data row5 col51\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col52\" class=\"data row5 col52\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row5_col53\" class=\"data row5 col53\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_81b2f_row6_col0\" class=\"data row6 col0\" >0.51</td>\n",
       "      <td id=\"T_81b2f_row6_col1\" class=\"data row6 col1\" >342.59</td>\n",
       "      <td id=\"T_81b2f_row6_col2\" class=\"data row6 col2\" >64.76</td>\n",
       "      <td id=\"T_81b2f_row6_col3\" class=\"data row6 col3\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row6_col4\" class=\"data row6 col4\" >5.00</td>\n",
       "      <td id=\"T_81b2f_row6_col5\" class=\"data row6 col5\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col6\" class=\"data row6 col6\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col7\" class=\"data row6 col7\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col8\" class=\"data row6 col8\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col9\" class=\"data row6 col9\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col10\" class=\"data row6 col10\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col11\" class=\"data row6 col11\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col12\" class=\"data row6 col12\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col13\" class=\"data row6 col13\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col14\" class=\"data row6 col14\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row6_col15\" class=\"data row6 col15\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col16\" class=\"data row6 col16\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col17\" class=\"data row6 col17\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col18\" class=\"data row6 col18\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col19\" class=\"data row6 col19\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col20\" class=\"data row6 col20\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col21\" class=\"data row6 col21\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col22\" class=\"data row6 col22\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col23\" class=\"data row6 col23\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col24\" class=\"data row6 col24\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col25\" class=\"data row6 col25\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col26\" class=\"data row6 col26\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col27\" class=\"data row6 col27\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col28\" class=\"data row6 col28\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col29\" class=\"data row6 col29\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col30\" class=\"data row6 col30\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col31\" class=\"data row6 col31\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col32\" class=\"data row6 col32\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col33\" class=\"data row6 col33\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col34\" class=\"data row6 col34\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col35\" class=\"data row6 col35\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col36\" class=\"data row6 col36\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row6_col37\" class=\"data row6 col37\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col38\" class=\"data row6 col38\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col39\" class=\"data row6 col39\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col40\" class=\"data row6 col40\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col41\" class=\"data row6 col41\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col42\" class=\"data row6 col42\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col43\" class=\"data row6 col43\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col44\" class=\"data row6 col44\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col45\" class=\"data row6 col45\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col46\" class=\"data row6 col46\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col47\" class=\"data row6 col47\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col48\" class=\"data row6 col48\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col49\" class=\"data row6 col49\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col50\" class=\"data row6 col50\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col51\" class=\"data row6 col51\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col52\" class=\"data row6 col52\" >0.00</td>\n",
       "      <td id=\"T_81b2f_row6_col53\" class=\"data row6 col53\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81b2f_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_81b2f_row7_col0\" class=\"data row7 col0\" >0.95</td>\n",
       "      <td id=\"T_81b2f_row7_col1\" class=\"data row7 col1\" >453.15</td>\n",
       "      <td id=\"T_81b2f_row7_col2\" class=\"data row7 col2\" >499.90</td>\n",
       "      <td id=\"T_81b2f_row7_col3\" class=\"data row7 col3\" >7.00</td>\n",
       "      <td id=\"T_81b2f_row7_col4\" class=\"data row7 col4\" >28.00</td>\n",
       "      <td id=\"T_81b2f_row7_col5\" class=\"data row7 col5\" >3.00</td>\n",
       "      <td id=\"T_81b2f_row7_col6\" class=\"data row7 col6\" >2.00</td>\n",
       "      <td id=\"T_81b2f_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col8\" class=\"data row7 col8\" >5.00</td>\n",
       "      <td id=\"T_81b2f_row7_col9\" class=\"data row7 col9\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col10\" class=\"data row7 col10\" >3.00</td>\n",
       "      <td id=\"T_81b2f_row7_col11\" class=\"data row7 col11\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col12\" class=\"data row7 col12\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col13\" class=\"data row7 col13\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col14\" class=\"data row7 col14\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col15\" class=\"data row7 col15\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col16\" class=\"data row7 col16\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col17\" class=\"data row7 col17\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col18\" class=\"data row7 col18\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col19\" class=\"data row7 col19\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col20\" class=\"data row7 col20\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col21\" class=\"data row7 col21\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col22\" class=\"data row7 col22\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col23\" class=\"data row7 col23\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col24\" class=\"data row7 col24\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col25\" class=\"data row7 col25\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col26\" class=\"data row7 col26\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col27\" class=\"data row7 col27\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col28\" class=\"data row7 col28\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col29\" class=\"data row7 col29\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col30\" class=\"data row7 col30\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col31\" class=\"data row7 col31\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col32\" class=\"data row7 col32\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col33\" class=\"data row7 col33\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col34\" class=\"data row7 col34\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col35\" class=\"data row7 col35\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col36\" class=\"data row7 col36\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col37\" class=\"data row7 col37\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col38\" class=\"data row7 col38\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col39\" class=\"data row7 col39\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col40\" class=\"data row7 col40\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col41\" class=\"data row7 col41\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col42\" class=\"data row7 col42\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col43\" class=\"data row7 col43\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col44\" class=\"data row7 col44\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col45\" class=\"data row7 col45\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col46\" class=\"data row7 col46\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col47\" class=\"data row7 col47\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col48\" class=\"data row7 col48\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col49\" class=\"data row7 col49\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col50\" class=\"data row7 col50\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col51\" class=\"data row7 col51\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col52\" class=\"data row7 col52\" >1.00</td>\n",
       "      <td id=\"T_81b2f_row7_col53\" class=\"data row7 col53\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9a481ea770>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataCO2f='../DS4B-CO2-data'+'/'+'dataCO2.csv'\n",
    "dataCO2=pd.read_csv(dataCO2f,sep=\";\",header=0)\n",
    "display(dataCO2)\n",
    "# describe() generates descriptive statistics\n",
    "display(dataCO2.describe().style.format(\"{0:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf1e66-0756-47f2-928d-d0d578613bba",
   "metadata": {},
   "source": [
    "## 2. Assessment of the stability of the original ML algorithm of Song *et al*. by *K*-fold cross validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b3ba1f-2f90-441f-b931-28bc9e64748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# separation of the data set into two subsets: (1) training of the ANN & (2) test of the ANN\n",
    "# library used: pandas\n",
    "xdata = dataCO2.drop(['IL','cation','anion','x_CO2'],axis=1)\n",
    "ydata = dataCO2['x_CO2']\n",
    "\n",
    "#######################################################################################\n",
    "# ANN: 1 input layer (53 neurons) / 2 hidden layers (20 and 7 neurons) / 1 output layer (1 neuron) \n",
    "# library used: keras\n",
    "\n",
    "def defANN(shape,acthL):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape, name='iLayer'))\n",
    "    model.add(keras.layers.Dense(7, activation=acthL, name='hLayer'))\n",
    "    model.add(keras.layers.Dense(1, name='oLayer'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss      = 'mse',\n",
    "                  metrics   = ['mae', 'mse'] )\n",
    "    return model\n",
    "\n",
    "acthL='tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3138b7-5dc7-4804-93cb-caab9887319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91mFold 0\u001b[0m\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 14:53:14.431587: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 1ms/step - loss: 0.2517 - mae: 0.3465 - mse: 0.2517 - val_loss: 0.0444 - val_mae: 0.1499 - val_mse: 0.0444\n",
      "Epoch 2/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1213 - mse: 0.0242 - val_loss: 0.0202 - val_mae: 0.1143 - val_mse: 0.0202\n",
      "Epoch 3/200\n",
      "324/324 [==============================] - 1s 2ms/step - loss: 0.0177 - mae: 0.1057 - mse: 0.0177 - val_loss: 0.0154 - val_mae: 0.0961 - val_mse: 0.0154\n",
      "Epoch 4/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0128 - mae: 0.0873 - mse: 0.0128 - val_loss: 0.0106 - val_mae: 0.0788 - val_mse: 0.0106\n",
      "Epoch 5/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0095 - mae: 0.0747 - mse: 0.0095 - val_loss: 0.0089 - val_mae: 0.0714 - val_mse: 0.0089\n",
      "Epoch 6/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0088 - mae: 0.0715 - mse: 0.0088 - val_loss: 0.0103 - val_mae: 0.0779 - val_mse: 0.0103\n",
      "Epoch 7/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0077 - mae: 0.0665 - mse: 0.0077 - val_loss: 0.0073 - val_mae: 0.0630 - val_mse: 0.0073\n",
      "Epoch 8/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0074 - mae: 0.0650 - mse: 0.0074 - val_loss: 0.0090 - val_mae: 0.0735 - val_mse: 0.0090\n",
      "Epoch 9/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0621 - mse: 0.0068 - val_loss: 0.0065 - val_mae: 0.0586 - val_mse: 0.0065\n",
      "Epoch 10/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0593 - mse: 0.0063 - val_loss: 0.0070 - val_mae: 0.0646 - val_mse: 0.0070\n",
      "Epoch 11/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0060 - mae: 0.0580 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0560 - val_mse: 0.0059\n",
      "Epoch 12/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0057 - mae: 0.0568 - mse: 0.0057 - val_loss: 0.0054 - val_mae: 0.0544 - val_mse: 0.0054\n",
      "Epoch 13/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0052 - mae: 0.0538 - mse: 0.0052 - val_loss: 0.0066 - val_mae: 0.0635 - val_mse: 0.0066\n",
      "Epoch 14/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0050 - mae: 0.0528 - mse: 0.0050 - val_loss: 0.0041 - val_mae: 0.0466 - val_mse: 0.0041\n",
      "Epoch 15/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0046 - mae: 0.0515 - mse: 0.0046 - val_loss: 0.0037 - val_mae: 0.0458 - val_mse: 0.0037\n",
      "Epoch 16/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0487 - mse: 0.0041 - val_loss: 0.0038 - val_mae: 0.0456 - val_mse: 0.0038\n",
      "Epoch 17/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0038 - mae: 0.0467 - mse: 0.0038 - val_loss: 0.0040 - val_mae: 0.0472 - val_mse: 0.0040\n",
      "Epoch 18/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0038 - mae: 0.0471 - mse: 0.0038 - val_loss: 0.0051 - val_mae: 0.0561 - val_mse: 0.0051\n",
      "Epoch 19/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0040 - mae: 0.0488 - mse: 0.0040 - val_loss: 0.0034 - val_mae: 0.0437 - val_mse: 0.0034\n",
      "Epoch 20/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0489 - mse: 0.0041 - val_loss: 0.0038 - val_mae: 0.0460 - val_mse: 0.0038\n",
      "Epoch 21/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0433 - mse: 0.0033 - val_loss: 0.0029 - val_mae: 0.0408 - val_mse: 0.0029\n",
      "Epoch 22/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0438 - mse: 0.0033 - val_loss: 0.0070 - val_mae: 0.0685 - val_mse: 0.0070\n",
      "Epoch 23/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0465 - mse: 0.0037 - val_loss: 0.0030 - val_mae: 0.0416 - val_mse: 0.0030\n",
      "Epoch 24/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0434 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0433 - val_mse: 0.0034\n",
      "Epoch 25/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0452 - mse: 0.0035 - val_loss: 0.0027 - val_mae: 0.0386 - val_mse: 0.0027\n",
      "Epoch 26/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0452 - mse: 0.0035 - val_loss: 0.0043 - val_mae: 0.0509 - val_mse: 0.0043\n",
      "Epoch 27/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0430 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0444 - val_mse: 0.0033\n",
      "Epoch 28/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0424 - mse: 0.0032 - val_loss: 0.0027 - val_mae: 0.0384 - val_mse: 0.0027\n",
      "Epoch 29/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0442 - mse: 0.0034 - val_loss: 0.0028 - val_mae: 0.0386 - val_mse: 0.0028\n",
      "Epoch 30/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0439 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0449 - val_mse: 0.0034\n",
      "Epoch 31/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0430 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0456 - val_mse: 0.0034\n",
      "Epoch 32/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0415 - mse: 0.0030 - val_loss: 0.0027 - val_mae: 0.0382 - val_mse: 0.0027\n",
      "Epoch 33/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0429 - mse: 0.0032 - val_loss: 0.0027 - val_mae: 0.0385 - val_mse: 0.0027\n",
      "Epoch 34/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0445 - mse: 0.0034 - val_loss: 0.0030 - val_mae: 0.0426 - val_mse: 0.0030\n",
      "Epoch 35/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0430 - mse: 0.0032 - val_loss: 0.0029 - val_mae: 0.0391 - val_mse: 0.0029\n",
      "Epoch 36/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0443 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0449 - val_mse: 0.0036\n",
      "Epoch 37/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0428 - mse: 0.0032 - val_loss: 0.0026 - val_mae: 0.0380 - val_mse: 0.0026\n",
      "Epoch 38/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0029 - mae: 0.0410 - mse: 0.0029 - val_loss: 0.0032 - val_mae: 0.0449 - val_mse: 0.0032\n",
      "Epoch 39/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0427 - mse: 0.0032 - val_loss: 0.0026 - val_mae: 0.0378 - val_mse: 0.0026\n",
      "Epoch 40/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0031 - mae: 0.0425 - mse: 0.0031 - val_loss: 0.0041 - val_mae: 0.0523 - val_mse: 0.0041\n",
      "Epoch 41/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0031 - mae: 0.0424 - mse: 0.0031 - val_loss: 0.0029 - val_mae: 0.0389 - val_mse: 0.0029\n",
      "Epoch 42/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0417 - mse: 0.0030 - val_loss: 0.0030 - val_mae: 0.0419 - val_mse: 0.0030\n",
      "Epoch 43/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0427 - mse: 0.0032 - val_loss: 0.0029 - val_mae: 0.0392 - val_mse: 0.0029\n",
      "Epoch 44/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0434 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0454 - val_mse: 0.0033\n",
      "Epoch 45/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0417 - mse: 0.0030 - val_loss: 0.0032 - val_mae: 0.0414 - val_mse: 0.0032\n",
      "Epoch 46/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0437 - mse: 0.0033 - val_loss: 0.0028 - val_mae: 0.0398 - val_mse: 0.0028\n",
      "Epoch 47/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0460 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0478 - val_mse: 0.0035\n",
      "Epoch 48/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0029 - mae: 0.0410 - mse: 0.0029 - val_loss: 0.0027 - val_mae: 0.0380 - val_mse: 0.0027\n",
      "Epoch 49/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0442 - mse: 0.0034 - val_loss: 0.0027 - val_mae: 0.0381 - val_mse: 0.0027\n",
      "Epoch 50/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0434 - mse: 0.0032 - val_loss: 0.0026 - val_mae: 0.0392 - val_mse: 0.0026\n",
      "Epoch 51/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0416 - mse: 0.0030 - val_loss: 0.0031 - val_mae: 0.0397 - val_mse: 0.0031\n",
      "Epoch 52/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0426 - mse: 0.0032 - val_loss: 0.0027 - val_mae: 0.0381 - val_mse: 0.0027\n",
      "Epoch 53/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0031 - mae: 0.0422 - mse: 0.0031 - val_loss: 0.0030 - val_mae: 0.0395 - val_mse: 0.0030\n",
      "Epoch 54/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0427 - mse: 0.0032 - val_loss: 0.0029 - val_mae: 0.0390 - val_mse: 0.0029\n",
      "Epoch 54: early stopping\n",
      "253/253 [==============================] - 0s 602us/step\n",
      "64/64 [==============================] - 0s 657us/step\n",
      "\n",
      "xCO2(predicted) - xCO2(actual)\n",
      "Train. mean:  -0.013106341822388505    std:  0.04958889458102542    MAE:  0.03757151238859289     R2:  0.9777932853368186\n",
      "Test. mean:  -0.014869639267192541    std:  0.05133417984572081    MAE:  0.03904120444124052     R2:  0.9769485511815578\n",
      "\u001b[1m\u001b[91mFold 1\u001b[0m\n",
      "Epoch 1/200\n",
      "324/324 [==============================] - 1s 1ms/step - loss: 0.1574 - mae: 0.2690 - mse: 0.1574 - val_loss: 0.0752 - val_mae: 0.2119 - val_mse: 0.0752\n",
      "Epoch 2/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0633 - mae: 0.2028 - mse: 0.0633 - val_loss: 0.0576 - val_mae: 0.1948 - val_mse: 0.0576\n",
      "Epoch 3/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0574 - mae: 0.1954 - mse: 0.0574 - val_loss: 0.0541 - val_mae: 0.1886 - val_mse: 0.0541\n",
      "Epoch 4/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0533 - mae: 0.1915 - mse: 0.0533 - val_loss: 0.0488 - val_mae: 0.1855 - val_mse: 0.0488\n",
      "Epoch 5/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0533 - mae: 0.1908 - mse: 0.0533 - val_loss: 0.0497 - val_mae: 0.1881 - val_mse: 0.0497\n",
      "Epoch 6/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0508 - mae: 0.1874 - mse: 0.0508 - val_loss: 0.0477 - val_mae: 0.1826 - val_mse: 0.0477\n",
      "Epoch 7/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0481 - mae: 0.1826 - mse: 0.0481 - val_loss: 0.0461 - val_mae: 0.1786 - val_mse: 0.0461\n",
      "Epoch 8/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.1808 - mse: 0.0475 - val_loss: 0.0445 - val_mae: 0.1772 - val_mse: 0.0445\n",
      "Epoch 9/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0477 - mae: 0.1808 - mse: 0.0477 - val_loss: 0.0497 - val_mae: 0.1826 - val_mse: 0.0497\n",
      "Epoch 10/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0469 - mae: 0.1804 - mse: 0.0469 - val_loss: 0.0447 - val_mae: 0.1771 - val_mse: 0.0447\n",
      "Epoch 11/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0455 - mae: 0.1767 - mse: 0.0455 - val_loss: 0.0425 - val_mae: 0.1705 - val_mse: 0.0425\n",
      "Epoch 12/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0409 - mae: 0.1675 - mse: 0.0409 - val_loss: 0.0395 - val_mae: 0.1621 - val_mse: 0.0395\n",
      "Epoch 13/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0351 - mae: 0.1524 - mse: 0.0351 - val_loss: 0.0338 - val_mae: 0.1482 - val_mse: 0.0338\n",
      "Epoch 14/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0309 - mae: 0.1408 - mse: 0.0309 - val_loss: 0.0233 - val_mae: 0.1242 - val_mse: 0.0233\n",
      "Epoch 15/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0222 - mae: 0.1213 - mse: 0.0222 - val_loss: 0.0211 - val_mae: 0.1179 - val_mse: 0.0211\n",
      "Epoch 16/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.1174 - mse: 0.0208 - val_loss: 0.0213 - val_mae: 0.1180 - val_mse: 0.0213\n",
      "Epoch 17/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1161 - mse: 0.0206 - val_loss: 0.0215 - val_mae: 0.1193 - val_mse: 0.0215\n",
      "Epoch 18/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0203 - mae: 0.1158 - mse: 0.0203 - val_loss: 0.0205 - val_mae: 0.1146 - val_mse: 0.0205\n",
      "Epoch 19/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0203 - mae: 0.1150 - mse: 0.0203 - val_loss: 0.0200 - val_mae: 0.1139 - val_mse: 0.0200\n",
      "Epoch 20/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.1131 - mse: 0.0195 - val_loss: 0.0199 - val_mae: 0.1144 - val_mse: 0.0199\n",
      "Epoch 21/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0191 - mae: 0.1119 - mse: 0.0191 - val_loss: 0.0196 - val_mae: 0.1123 - val_mse: 0.0196\n",
      "Epoch 22/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.1107 - mse: 0.0187 - val_loss: 0.0192 - val_mae: 0.1114 - val_mse: 0.0192\n",
      "Epoch 23/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.1113 - mse: 0.0190 - val_loss: 0.0204 - val_mae: 0.1160 - val_mse: 0.0204\n",
      "Epoch 24/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0181 - mae: 0.1087 - mse: 0.0181 - val_loss: 0.0182 - val_mae: 0.1090 - val_mse: 0.0182\n",
      "Epoch 25/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0174 - mae: 0.1063 - mse: 0.0174 - val_loss: 0.0182 - val_mae: 0.1066 - val_mse: 0.0182\n",
      "Epoch 26/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.1044 - mse: 0.0170 - val_loss: 0.0167 - val_mae: 0.1027 - val_mse: 0.0167\n",
      "Epoch 27/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.1045 - mse: 0.0172 - val_loss: 0.0162 - val_mae: 0.1002 - val_mse: 0.0162\n",
      "Epoch 28/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.1008 - mse: 0.0163 - val_loss: 0.0158 - val_mae: 0.0981 - val_mse: 0.0158\n",
      "Epoch 29/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0959 - mse: 0.0151 - val_loss: 0.0143 - val_mae: 0.0926 - val_mse: 0.0143\n",
      "Epoch 30/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0908 - mse: 0.0140 - val_loss: 0.0129 - val_mae: 0.0855 - val_mse: 0.0129\n",
      "Epoch 31/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0843 - mse: 0.0123 - val_loss: 0.0117 - val_mae: 0.0822 - val_mse: 0.0117\n",
      "Epoch 32/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0105 - mae: 0.0777 - mse: 0.0105 - val_loss: 0.0089 - val_mae: 0.0710 - val_mse: 0.0089\n",
      "Epoch 33/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0095 - mae: 0.0737 - mse: 0.0095 - val_loss: 0.0096 - val_mae: 0.0741 - val_mse: 0.0096\n",
      "Epoch 34/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0085 - mae: 0.0697 - mse: 0.0085 - val_loss: 0.0080 - val_mae: 0.0688 - val_mse: 0.0080\n",
      "Epoch 35/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0082 - mae: 0.0684 - mse: 0.0082 - val_loss: 0.0076 - val_mae: 0.0652 - val_mse: 0.0076\n",
      "Epoch 36/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0083 - mae: 0.0687 - mse: 0.0083 - val_loss: 0.0094 - val_mae: 0.0780 - val_mse: 0.0094\n",
      "Epoch 37/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0083 - mae: 0.0688 - mse: 0.0083 - val_loss: 0.0073 - val_mae: 0.0645 - val_mse: 0.0073\n",
      "Epoch 38/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0082 - mae: 0.0689 - mse: 0.0082 - val_loss: 0.0073 - val_mae: 0.0649 - val_mse: 0.0073\n",
      "Epoch 39/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0079 - mae: 0.0674 - mse: 0.0079 - val_loss: 0.0076 - val_mae: 0.0653 - val_mse: 0.0076\n",
      "Epoch 40/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0078 - mae: 0.0670 - mse: 0.0078 - val_loss: 0.0073 - val_mae: 0.0637 - val_mse: 0.0073\n",
      "Epoch 41/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0078 - mae: 0.0671 - mse: 0.0078 - val_loss: 0.0084 - val_mae: 0.0722 - val_mse: 0.0084\n",
      "Epoch 42/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0079 - mae: 0.0677 - mse: 0.0079 - val_loss: 0.0092 - val_mae: 0.0730 - val_mse: 0.0092\n",
      "Epoch 43/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0077 - mae: 0.0665 - mse: 0.0077 - val_loss: 0.0073 - val_mae: 0.0636 - val_mse: 0.0073\n",
      "Epoch 44/200\n",
      "324/324 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0661 - mse: 0.0076 - val_loss: 0.0076 - val_mae: 0.0685 - val_mse: 0.0076\n",
      "Epoch 45/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0657 - mse: 0.0075 - val_loss: 0.0069 - val_mae: 0.0641 - val_mse: 0.0069\n",
      "Epoch 46/200\n",
      "324/324 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0665 - mse: 0.0077 - val_loss: 0.0069 - val_mae: 0.0628 - val_mse: 0.0069\n",
      "Epoch 47/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0655 - mse: 0.0075 - val_loss: 0.0068 - val_mae: 0.0634 - val_mse: 0.0068\n",
      "Epoch 48/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0074 - mae: 0.0650 - mse: 0.0074 - val_loss: 0.0072 - val_mae: 0.0624 - val_mse: 0.0072\n",
      "Epoch 49/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0078 - mae: 0.0670 - mse: 0.0078 - val_loss: 0.0073 - val_mae: 0.0637 - val_mse: 0.0073\n",
      "Epoch 50/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0653 - mse: 0.0075 - val_loss: 0.0070 - val_mae: 0.0648 - val_mse: 0.0070\n",
      "Epoch 51/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0074 - mae: 0.0649 - mse: 0.0074 - val_loss: 0.0068 - val_mae: 0.0608 - val_mse: 0.0068\n",
      "Epoch 52/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0655 - mse: 0.0075 - val_loss: 0.0078 - val_mae: 0.0705 - val_mse: 0.0078\n",
      "Epoch 53/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0072 - mae: 0.0639 - mse: 0.0072 - val_loss: 0.0072 - val_mae: 0.0665 - val_mse: 0.0072\n",
      "Epoch 54/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0073 - mae: 0.0643 - mse: 0.0073 - val_loss: 0.0081 - val_mae: 0.0675 - val_mse: 0.0081\n",
      "Epoch 55/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0073 - mae: 0.0645 - mse: 0.0073 - val_loss: 0.0072 - val_mae: 0.0638 - val_mse: 0.0072\n",
      "Epoch 56/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0071 - mae: 0.0634 - mse: 0.0071 - val_loss: 0.0065 - val_mae: 0.0611 - val_mse: 0.0065\n",
      "Epoch 57/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0629 - mse: 0.0070 - val_loss: 0.0065 - val_mae: 0.0594 - val_mse: 0.0065\n",
      "Epoch 58/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0073 - mae: 0.0650 - mse: 0.0073 - val_loss: 0.0067 - val_mae: 0.0605 - val_mse: 0.0067\n",
      "Epoch 59/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0628 - mse: 0.0070 - val_loss: 0.0067 - val_mae: 0.0631 - val_mse: 0.0067\n",
      "Epoch 60/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0618 - mse: 0.0068 - val_loss: 0.0063 - val_mae: 0.0595 - val_mse: 0.0063\n",
      "Epoch 61/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0071 - mae: 0.0637 - mse: 0.0071 - val_loss: 0.0063 - val_mae: 0.0588 - val_mse: 0.0063\n",
      "Epoch 62/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0631 - mse: 0.0070 - val_loss: 0.0098 - val_mae: 0.0779 - val_mse: 0.0098\n",
      "Epoch 63/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0069 - mae: 0.0628 - mse: 0.0069 - val_loss: 0.0064 - val_mae: 0.0599 - val_mse: 0.0064\n",
      "Epoch 64/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0623 - mse: 0.0068 - val_loss: 0.0064 - val_mae: 0.0604 - val_mse: 0.0064\n",
      "Epoch 65/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0069 - mae: 0.0627 - mse: 0.0069 - val_loss: 0.0065 - val_mae: 0.0622 - val_mse: 0.0065\n",
      "Epoch 66/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0612 - mse: 0.0066 - val_loss: 0.0061 - val_mae: 0.0592 - val_mse: 0.0061\n",
      "Epoch 67/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0614 - mse: 0.0066 - val_loss: 0.0061 - val_mae: 0.0592 - val_mse: 0.0061\n",
      "Epoch 68/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0615 - mse: 0.0066 - val_loss: 0.0063 - val_mae: 0.0613 - val_mse: 0.0063\n",
      "Epoch 69/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0623 - mse: 0.0068 - val_loss: 0.0125 - val_mae: 0.0926 - val_mse: 0.0125\n",
      "Epoch 70/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0624 - mse: 0.0068 - val_loss: 0.0070 - val_mae: 0.0661 - val_mse: 0.0070\n",
      "Epoch 71/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0612 - mse: 0.0066 - val_loss: 0.0065 - val_mae: 0.0614 - val_mse: 0.0065\n",
      "Epoch 72/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0613 - mse: 0.0066 - val_loss: 0.0077 - val_mae: 0.0680 - val_mse: 0.0077\n",
      "Epoch 73/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0610 - mse: 0.0065 - val_loss: 0.0061 - val_mae: 0.0582 - val_mse: 0.0061\n",
      "Epoch 74/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0610 - mse: 0.0065 - val_loss: 0.0059 - val_mae: 0.0577 - val_mse: 0.0059\n",
      "Epoch 75/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0614 - mse: 0.0066 - val_loss: 0.0061 - val_mae: 0.0598 - val_mse: 0.0061\n",
      "Epoch 76/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0603 - mse: 0.0064 - val_loss: 0.0064 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 77/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0602 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0572 - val_mse: 0.0059\n",
      "Epoch 78/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0619 - mse: 0.0067 - val_loss: 0.0063 - val_mae: 0.0615 - val_mse: 0.0063\n",
      "Epoch 79/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0611 - mse: 0.0065 - val_loss: 0.0064 - val_mae: 0.0603 - val_mse: 0.0064\n",
      "Epoch 80/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0615 - mse: 0.0066 - val_loss: 0.0098 - val_mae: 0.0811 - val_mse: 0.0098\n",
      "Epoch 81/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0617 - mse: 0.0066 - val_loss: 0.0060 - val_mae: 0.0574 - val_mse: 0.0060\n",
      "Epoch 82/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0608 - mse: 0.0065 - val_loss: 0.0068 - val_mae: 0.0627 - val_mse: 0.0068\n",
      "Epoch 83/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0604 - mse: 0.0064 - val_loss: 0.0062 - val_mae: 0.0603 - val_mse: 0.0062\n",
      "Epoch 84/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0597 - mse: 0.0063 - val_loss: 0.0058 - val_mae: 0.0573 - val_mse: 0.0058\n",
      "Epoch 85/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0606 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0571 - val_mse: 0.0059\n",
      "Epoch 86/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0624 - mse: 0.0067 - val_loss: 0.0059 - val_mae: 0.0579 - val_mse: 0.0059\n",
      "Epoch 87/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0609 - mse: 0.0065 - val_loss: 0.0061 - val_mae: 0.0605 - val_mse: 0.0061\n",
      "Epoch 88/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0602 - mse: 0.0064 - val_loss: 0.0063 - val_mae: 0.0597 - val_mse: 0.0063\n",
      "Epoch 89/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0606 - mse: 0.0064 - val_loss: 0.0063 - val_mae: 0.0595 - val_mse: 0.0063\n",
      "Epoch 90/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0597 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0577 - val_mse: 0.0059\n",
      "Epoch 91/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0597 - mse: 0.0063 - val_loss: 0.0064 - val_mae: 0.0609 - val_mse: 0.0064\n",
      "Epoch 92/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0620 - mse: 0.0066 - val_loss: 0.0071 - val_mae: 0.0673 - val_mse: 0.0071\n",
      "Epoch 93/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0607 - mse: 0.0065 - val_loss: 0.0065 - val_mae: 0.0637 - val_mse: 0.0065\n",
      "Epoch 94/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0622 - mse: 0.0067 - val_loss: 0.0074 - val_mae: 0.0690 - val_mse: 0.0074\n",
      "Epoch 95/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0604 - mse: 0.0064 - val_loss: 0.0060 - val_mae: 0.0578 - val_mse: 0.0060\n",
      "Epoch 96/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0623 - mse: 0.0067 - val_loss: 0.0084 - val_mae: 0.0711 - val_mse: 0.0084\n",
      "Epoch 97/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0605 - mse: 0.0064 - val_loss: 0.0058 - val_mae: 0.0579 - val_mse: 0.0058\n",
      "Epoch 98/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0607 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0568 - val_mse: 0.0059\n",
      "Epoch 99/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0617 - mse: 0.0066 - val_loss: 0.0087 - val_mae: 0.0735 - val_mse: 0.0087\n",
      "Epoch 100/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0613 - mse: 0.0066 - val_loss: 0.0068 - val_mae: 0.0651 - val_mse: 0.0068\n",
      "Epoch 101/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0597 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0576 - val_mse: 0.0059\n",
      "Epoch 102/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0602 - mse: 0.0063 - val_loss: 0.0065 - val_mae: 0.0632 - val_mse: 0.0065\n",
      "Epoch 103/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0606 - mse: 0.0064 - val_loss: 0.0064 - val_mae: 0.0600 - val_mse: 0.0064\n",
      "Epoch 104/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0594 - mse: 0.0062 - val_loss: 0.0057 - val_mae: 0.0569 - val_mse: 0.0057\n",
      "Epoch 105/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0606 - mse: 0.0064 - val_loss: 0.0057 - val_mae: 0.0567 - val_mse: 0.0057\n",
      "Epoch 106/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0605 - mse: 0.0064 - val_loss: 0.0071 - val_mae: 0.0669 - val_mse: 0.0071\n",
      "Epoch 107/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0593 - mse: 0.0062 - val_loss: 0.0060 - val_mae: 0.0590 - val_mse: 0.0060\n",
      "Epoch 108/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0600 - mse: 0.0063 - val_loss: 0.0057 - val_mae: 0.0564 - val_mse: 0.0057\n",
      "Epoch 109/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0597 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0589 - val_mse: 0.0059\n",
      "Epoch 110/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0611 - mse: 0.0065 - val_loss: 0.0075 - val_mae: 0.0700 - val_mse: 0.0075\n",
      "Epoch 111/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0605 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0584 - val_mse: 0.0059\n",
      "Epoch 112/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0600 - mse: 0.0063 - val_loss: 0.0064 - val_mae: 0.0598 - val_mse: 0.0064\n",
      "Epoch 113/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0598 - mse: 0.0063 - val_loss: 0.0063 - val_mae: 0.0593 - val_mse: 0.0063\n",
      "Epoch 114/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0612 - mse: 0.0065 - val_loss: 0.0079 - val_mae: 0.0720 - val_mse: 0.0079\n",
      "Epoch 115/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0594 - mse: 0.0062 - val_loss: 0.0074 - val_mae: 0.0690 - val_mse: 0.0074\n",
      "Epoch 116/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0595 - mse: 0.0062 - val_loss: 0.0061 - val_mae: 0.0585 - val_mse: 0.0061\n",
      "Epoch 117/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0595 - mse: 0.0062 - val_loss: 0.0057 - val_mae: 0.0572 - val_mse: 0.0057\n",
      "Epoch 118/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0601 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0577 - val_mse: 0.0059\n",
      "Epoch 119/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0599 - mse: 0.0063 - val_loss: 0.0057 - val_mae: 0.0568 - val_mse: 0.0057\n",
      "Epoch 120/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0604 - mse: 0.0064 - val_loss: 0.0058 - val_mae: 0.0584 - val_mse: 0.0058\n",
      "Epoch 121/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0585 - mse: 0.0061 - val_loss: 0.0057 - val_mae: 0.0570 - val_mse: 0.0057\n",
      "Epoch 122/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0605 - mse: 0.0064 - val_loss: 0.0057 - val_mae: 0.0566 - val_mse: 0.0057\n",
      "Epoch 123/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0602 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0590 - val_mse: 0.0059\n",
      "Epoch 124/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0595 - mse: 0.0062 - val_loss: 0.0057 - val_mae: 0.0562 - val_mse: 0.0057\n",
      "Epoch 125/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0603 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0573 - val_mse: 0.0059\n",
      "Epoch 126/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0607 - mse: 0.0064 - val_loss: 0.0066 - val_mae: 0.0611 - val_mse: 0.0066\n",
      "Epoch 127/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0583 - mse: 0.0061 - val_loss: 0.0058 - val_mae: 0.0579 - val_mse: 0.0058\n",
      "Epoch 128/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0599 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0579 - val_mse: 0.0059\n",
      "Epoch 129/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0589 - mse: 0.0061 - val_loss: 0.0058 - val_mae: 0.0582 - val_mse: 0.0058\n",
      "Epoch 130/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0627 - mse: 0.0067 - val_loss: 0.0069 - val_mae: 0.0637 - val_mse: 0.0069\n",
      "Epoch 131/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0603 - mse: 0.0063 - val_loss: 0.0066 - val_mae: 0.0613 - val_mse: 0.0066\n",
      "Epoch 132/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0592 - mse: 0.0062 - val_loss: 0.0068 - val_mae: 0.0653 - val_mse: 0.0068\n",
      "Epoch 133/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0060 - mae: 0.0584 - mse: 0.0060 - val_loss: 0.0072 - val_mae: 0.0654 - val_mse: 0.0072\n",
      "Epoch 134/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0599 - mse: 0.0063 - val_loss: 0.0084 - val_mae: 0.0746 - val_mse: 0.0084\n",
      "Epoch 135/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0592 - mse: 0.0062 - val_loss: 0.0065 - val_mae: 0.0609 - val_mse: 0.0065\n",
      "Epoch 136/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0595 - mse: 0.0062 - val_loss: 0.0056 - val_mae: 0.0561 - val_mse: 0.0056\n",
      "Epoch 137/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0591 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0577 - val_mse: 0.0059\n",
      "Epoch 138/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0060 - mae: 0.0580 - mse: 0.0060 - val_loss: 0.0061 - val_mae: 0.0606 - val_mse: 0.0061\n",
      "Epoch 139/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0599 - mse: 0.0063 - val_loss: 0.0057 - val_mae: 0.0572 - val_mse: 0.0057\n",
      "Epoch 140/200\n",
      "324/324 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0604 - mse: 0.0064 - val_loss: 0.0057 - val_mae: 0.0564 - val_mse: 0.0057\n",
      "Epoch 141/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0597 - mse: 0.0062 - val_loss: 0.0057 - val_mae: 0.0564 - val_mse: 0.0057\n",
      "Epoch 142/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0600 - mse: 0.0063 - val_loss: 0.0069 - val_mae: 0.0664 - val_mse: 0.0069\n",
      "Epoch 143/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0598 - mse: 0.0063 - val_loss: 0.0067 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 144/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0593 - mse: 0.0062 - val_loss: 0.0056 - val_mae: 0.0559 - val_mse: 0.0056\n",
      "Epoch 145/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0596 - mse: 0.0062 - val_loss: 0.0078 - val_mae: 0.0712 - val_mse: 0.0078\n",
      "Epoch 146/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0595 - mse: 0.0062 - val_loss: 0.0086 - val_mae: 0.0755 - val_mse: 0.0086\n",
      "Epoch 147/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0608 - mse: 0.0064 - val_loss: 0.0058 - val_mae: 0.0571 - val_mse: 0.0058\n",
      "Epoch 148/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0590 - mse: 0.0061 - val_loss: 0.0056 - val_mae: 0.0560 - val_mse: 0.0056\n",
      "Epoch 149/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0593 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0570 - val_mse: 0.0059\n",
      "Epoch 150/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0595 - mse: 0.0062 - val_loss: 0.0062 - val_mae: 0.0596 - val_mse: 0.0062\n",
      "Epoch 151/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0589 - mse: 0.0061 - val_loss: 0.0057 - val_mae: 0.0564 - val_mse: 0.0057\n",
      "Epoch 151: early stopping\n",
      "253/253 [==============================] - 0s 729us/step\n",
      "64/64 [==============================] - 0s 864us/step\n",
      "\n",
      "xCO2(predicted) - xCO2(actual)\n",
      "Train. mean:  0.005095100389361798    std:  0.07517410305650264    MAE:  0.05548650102608699     R2:  0.9484383530987123\n",
      "Test. mean:  0.005846355854642203    std:  0.07548618778524614    MAE:  0.056363583482652815     R2:  0.9474613056712414\n",
      "\u001b[1m\u001b[91mFold 2\u001b[0m\n",
      "Epoch 1/200\n",
      "324/324 [==============================] - 1s 2ms/step - loss: 0.0602 - mae: 0.2037 - mse: 0.0602 - val_loss: 0.0546 - val_mae: 0.1958 - val_mse: 0.0546\n",
      "Epoch 2/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0567 - mae: 0.2017 - mse: 0.0567 - val_loss: 0.0543 - val_mae: 0.1966 - val_mse: 0.0543\n",
      "Epoch 3/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2016 - mse: 0.0563 - val_loss: 0.0544 - val_mae: 0.1990 - val_mse: 0.0544\n",
      "Epoch 4/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2015 - mse: 0.0563 - val_loss: 0.0543 - val_mae: 0.1965 - val_mse: 0.0543\n",
      "Epoch 5/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2017 - mse: 0.0563 - val_loss: 0.0542 - val_mae: 0.1973 - val_mse: 0.0542\n",
      "Epoch 6/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2017 - mse: 0.0563 - val_loss: 0.0542 - val_mae: 0.1973 - val_mse: 0.0542\n",
      "Epoch 7/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2018 - mse: 0.0563 - val_loss: 0.0558 - val_mae: 0.1954 - val_mse: 0.0558\n",
      "Epoch 8/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0564 - mae: 0.2018 - mse: 0.0564 - val_loss: 0.0543 - val_mae: 0.1967 - val_mse: 0.0543\n",
      "Epoch 9/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2015 - mse: 0.0563 - val_loss: 0.0543 - val_mae: 0.1986 - val_mse: 0.0543\n",
      "Epoch 10/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2017 - mse: 0.0563 - val_loss: 0.0546 - val_mae: 0.1958 - val_mse: 0.0546\n",
      "Epoch 11/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0564 - mae: 0.2016 - mse: 0.0564 - val_loss: 0.0543 - val_mae: 0.1966 - val_mse: 0.0543\n",
      "Epoch 12/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2019 - mse: 0.0563 - val_loss: 0.0542 - val_mae: 0.1979 - val_mse: 0.0542\n",
      "Epoch 13/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2015 - mse: 0.0563 - val_loss: 0.0547 - val_mae: 0.1958 - val_mse: 0.0547\n",
      "Epoch 14/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0564 - mae: 0.2019 - mse: 0.0564 - val_loss: 0.0544 - val_mae: 0.1963 - val_mse: 0.0544\n",
      "Epoch 15/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0564 - mae: 0.2017 - mse: 0.0564 - val_loss: 0.0542 - val_mae: 0.1980 - val_mse: 0.0542\n",
      "Epoch 16/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2015 - mse: 0.0563 - val_loss: 0.0551 - val_mae: 0.1955 - val_mse: 0.0551\n",
      "Epoch 17/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2017 - mse: 0.0563 - val_loss: 0.0543 - val_mae: 0.1987 - val_mse: 0.0543\n",
      "Epoch 18/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2018 - mse: 0.0563 - val_loss: 0.0547 - val_mae: 0.1958 - val_mse: 0.0547\n",
      "Epoch 19/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.2016 - mse: 0.0563 - val_loss: 0.0542 - val_mae: 0.1971 - val_mse: 0.0542\n",
      "Epoch 20/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0564 - mae: 0.2017 - mse: 0.0564 - val_loss: 0.0548 - val_mae: 0.2009 - val_mse: 0.0548\n",
      "Epoch 20: early stopping\n",
      "253/253 [==============================] - 0s 728us/step\n",
      "64/64 [==============================] - 0s 851us/step\n",
      "\n",
      "xCO2(predicted) - xCO2(actual)\n",
      "Train. mean:  0.029365731707851773    std:  0.236973053156136    MAE:  0.20560684543273736     R2:  -0.025568422741942542\n",
      "Test. mean:  0.02452626507355171    std:  0.23284230935614172    MAE:  0.20089643311858746     R2:  nan\n",
      "\u001b[1m\u001b[91mFold 3\u001b[0m\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romuald/anaconda3/envs/ML/lib/python3.10/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/romuald/anaconda3/envs/ML/lib/python3.10/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/step - loss: 0.2162 - mae: 0.3680 - mse: 0.2162 - val_loss: 0.0424 - val_mae: 0.1665 - val_mse: 0.0424\n",
      "Epoch 2/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0321 - mae: 0.1398 - mse: 0.0321 - val_loss: 0.0248 - val_mae: 0.1224 - val_mse: 0.0248\n",
      "Epoch 3/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.1073 - mse: 0.0214 - val_loss: 0.0176 - val_mae: 0.0996 - val_mse: 0.0176\n",
      "Epoch 4/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0166 - mae: 0.0942 - mse: 0.0166 - val_loss: 0.0132 - val_mae: 0.0854 - val_mse: 0.0132\n",
      "Epoch 5/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0872 - mse: 0.0131 - val_loss: 0.0128 - val_mae: 0.0858 - val_mse: 0.0128\n",
      "Epoch 6/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0129 - mae: 0.0847 - mse: 0.0129 - val_loss: 0.0143 - val_mae: 0.0824 - val_mse: 0.0143\n",
      "Epoch 7/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0827 - mse: 0.0117 - val_loss: 0.0108 - val_mae: 0.0768 - val_mse: 0.0108\n",
      "Epoch 8/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0119 - mae: 0.0818 - mse: 0.0119 - val_loss: 0.0110 - val_mae: 0.0776 - val_mse: 0.0110\n",
      "Epoch 9/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0110 - mae: 0.0785 - mse: 0.0110 - val_loss: 0.0130 - val_mae: 0.0888 - val_mse: 0.0130\n",
      "Epoch 10/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0109 - mae: 0.0782 - mse: 0.0109 - val_loss: 0.0116 - val_mae: 0.0850 - val_mse: 0.0116\n",
      "Epoch 11/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0760 - mse: 0.0103 - val_loss: 0.0109 - val_mae: 0.0765 - val_mse: 0.0109\n",
      "Epoch 12/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0108 - mae: 0.0771 - mse: 0.0108 - val_loss: 0.0115 - val_mae: 0.0761 - val_mse: 0.0115\n",
      "Epoch 13/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0115 - mae: 0.0785 - mse: 0.0115 - val_loss: 0.0110 - val_mae: 0.0783 - val_mse: 0.0110\n",
      "Epoch 14/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0113 - mae: 0.0785 - mse: 0.0113 - val_loss: 0.0118 - val_mae: 0.0802 - val_mse: 0.0118\n",
      "Epoch 15/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0108 - mae: 0.0778 - mse: 0.0108 - val_loss: 0.0100 - val_mae: 0.0751 - val_mse: 0.0100\n",
      "Epoch 16/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0748 - mse: 0.0100 - val_loss: 0.0093 - val_mae: 0.0719 - val_mse: 0.0093\n",
      "Epoch 17/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0756 - mse: 0.0102 - val_loss: 0.0122 - val_mae: 0.0815 - val_mse: 0.0122\n",
      "Epoch 18/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0744 - mse: 0.0102 - val_loss: 0.0093 - val_mae: 0.0733 - val_mse: 0.0093\n",
      "Epoch 19/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0098 - mae: 0.0735 - mse: 0.0098 - val_loss: 0.0097 - val_mae: 0.0751 - val_mse: 0.0097\n",
      "Epoch 20/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0098 - mae: 0.0763 - mse: 0.0098 - val_loss: 0.0091 - val_mae: 0.0714 - val_mse: 0.0091\n",
      "Epoch 21/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0094 - mae: 0.0727 - mse: 0.0094 - val_loss: 0.0105 - val_mae: 0.0755 - val_mse: 0.0105\n",
      "Epoch 22/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0097 - mae: 0.0742 - mse: 0.0097 - val_loss: 0.0094 - val_mae: 0.0720 - val_mse: 0.0094\n",
      "Epoch 23/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0742 - mse: 0.0100 - val_loss: 0.0091 - val_mae: 0.0727 - val_mse: 0.0091\n",
      "Epoch 24/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0722 - mse: 0.0092 - val_loss: 0.0124 - val_mae: 0.0919 - val_mse: 0.0124\n",
      "Epoch 25/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0718 - mse: 0.0093 - val_loss: 0.0091 - val_mae: 0.0729 - val_mse: 0.0091\n",
      "Epoch 26/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0098 - mae: 0.0716 - mse: 0.0098 - val_loss: 0.0097 - val_mae: 0.0717 - val_mse: 0.0097\n",
      "Epoch 27/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0094 - mae: 0.0719 - mse: 0.0094 - val_loss: 0.0092 - val_mae: 0.0701 - val_mse: 0.0092\n",
      "Epoch 28/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0091 - mae: 0.0720 - mse: 0.0091 - val_loss: 0.0086 - val_mae: 0.0697 - val_mse: 0.0086\n",
      "Epoch 29/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0730 - mse: 0.0093 - val_loss: 0.0089 - val_mae: 0.0704 - val_mse: 0.0089\n",
      "Epoch 30/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0090 - mae: 0.0717 - mse: 0.0090 - val_loss: 0.0107 - val_mae: 0.0842 - val_mse: 0.0107\n",
      "Epoch 31/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0091 - mae: 0.0719 - mse: 0.0091 - val_loss: 0.0088 - val_mae: 0.0716 - val_mse: 0.0088\n",
      "Epoch 32/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0089 - mae: 0.0714 - mse: 0.0089 - val_loss: 0.0092 - val_mae: 0.0700 - val_mse: 0.0092\n",
      "Epoch 33/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0090 - mae: 0.0711 - mse: 0.0090 - val_loss: 0.0089 - val_mae: 0.0699 - val_mse: 0.0089\n",
      "Epoch 34/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0087 - mae: 0.0705 - mse: 0.0087 - val_loss: 0.0086 - val_mae: 0.0709 - val_mse: 0.0086\n",
      "Epoch 35/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0087 - mae: 0.0704 - mse: 0.0087 - val_loss: 0.0092 - val_mae: 0.0760 - val_mse: 0.0092\n",
      "Epoch 36/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0088 - mae: 0.0709 - mse: 0.0088 - val_loss: 0.0088 - val_mae: 0.0696 - val_mse: 0.0088\n",
      "Epoch 37/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0087 - mae: 0.0700 - mse: 0.0087 - val_loss: 0.0093 - val_mae: 0.0717 - val_mse: 0.0093\n",
      "Epoch 38/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0717 - mse: 0.0092 - val_loss: 0.0092 - val_mae: 0.0710 - val_mse: 0.0092\n",
      "Epoch 39/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0087 - mae: 0.0708 - mse: 0.0087 - val_loss: 0.0096 - val_mae: 0.0772 - val_mse: 0.0096\n",
      "Epoch 40/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0089 - mae: 0.0710 - mse: 0.0089 - val_loss: 0.0091 - val_mae: 0.0743 - val_mse: 0.0091\n",
      "Epoch 41/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0087 - mae: 0.0700 - mse: 0.0087 - val_loss: 0.0087 - val_mae: 0.0707 - val_mse: 0.0087\n",
      "Epoch 42/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0087 - mae: 0.0702 - mse: 0.0087 - val_loss: 0.0089 - val_mae: 0.0722 - val_mse: 0.0089\n",
      "Epoch 43/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0085 - mae: 0.0701 - mse: 0.0085 - val_loss: 0.0118 - val_mae: 0.0801 - val_mse: 0.0118\n",
      "Epoch 43: early stopping\n",
      "253/253 [==============================] - 0s 757us/step\n",
      "64/64 [==============================] - 0s 665us/step\n",
      "\n",
      "xCO2(predicted) - xCO2(actual)\n",
      "Train. mean:  -0.012503063336035777    std:  0.10605602045870174    MAE:  0.07714575915765792     R2:  0.8985444695259808\n",
      "Test. mean:  -0.009190333258624844    std:  0.10809328422665496    MAE:  0.08012092949843644     R2:  0.8992677609431967\n",
      "\u001b[1m\u001b[91mFold 4\u001b[0m\n",
      "Epoch 1/200\n",
      "324/324 [==============================] - 1s 1ms/step - loss: 0.5236 - mae: 0.4885 - mse: 0.5236 - val_loss: 0.0630 - val_mae: 0.2027 - val_mse: 0.0630\n",
      "Epoch 2/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0603 - mae: 0.2026 - mse: 0.0603 - val_loss: 0.0549 - val_mae: 0.1959 - val_mse: 0.0549\n",
      "Epoch 3/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0540 - mae: 0.1953 - mse: 0.0540 - val_loss: 0.0506 - val_mae: 0.1888 - val_mse: 0.0506\n",
      "Epoch 4/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0504 - mae: 0.1895 - mse: 0.0504 - val_loss: 0.0517 - val_mae: 0.1884 - val_mse: 0.0517\n",
      "Epoch 5/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0493 - mae: 0.1865 - mse: 0.0493 - val_loss: 0.0474 - val_mae: 0.1824 - val_mse: 0.0474\n",
      "Epoch 6/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0473 - mae: 0.1822 - mse: 0.0473 - val_loss: 0.0461 - val_mae: 0.1799 - val_mse: 0.0461\n",
      "Epoch 7/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0469 - mae: 0.1809 - mse: 0.0469 - val_loss: 0.0443 - val_mae: 0.1747 - val_mse: 0.0443\n",
      "Epoch 8/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0455 - mae: 0.1778 - mse: 0.0455 - val_loss: 0.0483 - val_mae: 0.1783 - val_mse: 0.0483\n",
      "Epoch 9/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0439 - mae: 0.1738 - mse: 0.0439 - val_loss: 0.0411 - val_mae: 0.1663 - val_mse: 0.0411\n",
      "Epoch 10/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0374 - mae: 0.1593 - mse: 0.0374 - val_loss: 0.0356 - val_mae: 0.1552 - val_mse: 0.0356\n",
      "Epoch 11/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.1408 - mse: 0.0298 - val_loss: 0.0242 - val_mae: 0.1252 - val_mse: 0.0242\n",
      "Epoch 12/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.1304 - mse: 0.0267 - val_loss: 0.0223 - val_mae: 0.1215 - val_mse: 0.0223\n",
      "Epoch 13/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.1246 - mse: 0.0233 - val_loss: 0.0220 - val_mae: 0.1212 - val_mse: 0.0220\n",
      "Epoch 14/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1224 - mse: 0.0226 - val_loss: 0.0217 - val_mae: 0.1195 - val_mse: 0.0217\n",
      "Epoch 15/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0223 - mae: 0.1213 - mse: 0.0223 - val_loss: 0.0212 - val_mae: 0.1187 - val_mse: 0.0212\n",
      "Epoch 16/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0216 - mae: 0.1194 - mse: 0.0216 - val_loss: 0.0208 - val_mae: 0.1178 - val_mse: 0.0208\n",
      "Epoch 17/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.1174 - mse: 0.0208 - val_loss: 0.0205 - val_mae: 0.1161 - val_mse: 0.0205\n",
      "Epoch 18/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.1166 - mse: 0.0207 - val_loss: 0.0212 - val_mae: 0.1192 - val_mse: 0.0212\n",
      "Epoch 19/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.1154 - mse: 0.0204 - val_loss: 0.0197 - val_mae: 0.1139 - val_mse: 0.0197\n",
      "Epoch 20/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.1132 - mse: 0.0197 - val_loss: 0.0191 - val_mae: 0.1119 - val_mse: 0.0191\n",
      "Epoch 21/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0191 - mae: 0.1114 - mse: 0.0191 - val_loss: 0.0182 - val_mae: 0.1091 - val_mse: 0.0182\n",
      "Epoch 22/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.1087 - mse: 0.0182 - val_loss: 0.0176 - val_mae: 0.1069 - val_mse: 0.0176\n",
      "Epoch 23/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0175 - mae: 0.1058 - mse: 0.0175 - val_loss: 0.0163 - val_mae: 0.1022 - val_mse: 0.0163\n",
      "Epoch 24/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.1010 - mse: 0.0162 - val_loss: 0.0152 - val_mae: 0.0980 - val_mse: 0.0152\n",
      "Epoch 25/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0986 - mse: 0.0158 - val_loss: 0.0141 - val_mae: 0.0911 - val_mse: 0.0141\n",
      "Epoch 26/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0916 - mse: 0.0140 - val_loss: 0.0123 - val_mae: 0.0864 - val_mse: 0.0123\n",
      "Epoch 27/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0120 - mae: 0.0854 - mse: 0.0120 - val_loss: 0.0106 - val_mae: 0.0774 - val_mse: 0.0106\n",
      "Epoch 28/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0773 - mse: 0.0102 - val_loss: 0.0091 - val_mae: 0.0723 - val_mse: 0.0091\n",
      "Epoch 29/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0088 - mae: 0.0711 - mse: 0.0088 - val_loss: 0.0084 - val_mae: 0.0682 - val_mse: 0.0084\n",
      "Epoch 30/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0083 - mae: 0.0682 - mse: 0.0083 - val_loss: 0.0092 - val_mae: 0.0744 - val_mse: 0.0092\n",
      "Epoch 31/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0082 - mae: 0.0682 - mse: 0.0082 - val_loss: 0.0077 - val_mae: 0.0661 - val_mse: 0.0077\n",
      "Epoch 32/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0078 - mae: 0.0664 - mse: 0.0078 - val_loss: 0.0076 - val_mae: 0.0647 - val_mse: 0.0076\n",
      "Epoch 33/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0078 - mae: 0.0663 - mse: 0.0078 - val_loss: 0.0076 - val_mae: 0.0670 - val_mse: 0.0076\n",
      "Epoch 34/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0081 - mae: 0.0691 - mse: 0.0081 - val_loss: 0.0124 - val_mae: 0.0881 - val_mse: 0.0124\n",
      "Epoch 35/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0079 - mae: 0.0670 - mse: 0.0079 - val_loss: 0.0075 - val_mae: 0.0659 - val_mse: 0.0075\n",
      "Epoch 36/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0653 - mse: 0.0075 - val_loss: 0.0075 - val_mae: 0.0654 - val_mse: 0.0075\n",
      "Epoch 37/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0077 - mae: 0.0664 - mse: 0.0077 - val_loss: 0.0082 - val_mae: 0.0674 - val_mse: 0.0082\n",
      "Epoch 38/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0074 - mae: 0.0650 - mse: 0.0074 - val_loss: 0.0076 - val_mae: 0.0671 - val_mse: 0.0076\n",
      "Epoch 39/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0076 - mae: 0.0658 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0643 - val_mse: 0.0075\n",
      "Epoch 40/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0075 - mae: 0.0655 - mse: 0.0075 - val_loss: 0.0072 - val_mae: 0.0638 - val_mse: 0.0072\n",
      "Epoch 41/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0072 - mae: 0.0636 - mse: 0.0072 - val_loss: 0.0071 - val_mae: 0.0625 - val_mse: 0.0071\n",
      "Epoch 42/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0073 - mae: 0.0643 - mse: 0.0073 - val_loss: 0.0075 - val_mae: 0.0664 - val_mse: 0.0075\n",
      "Epoch 43/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0072 - mae: 0.0638 - mse: 0.0072 - val_loss: 0.0071 - val_mae: 0.0626 - val_mse: 0.0071\n",
      "Epoch 44/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0071 - mae: 0.0631 - mse: 0.0071 - val_loss: 0.0073 - val_mae: 0.0630 - val_mse: 0.0073\n",
      "Epoch 45/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0071 - mae: 0.0632 - mse: 0.0071 - val_loss: 0.0075 - val_mae: 0.0640 - val_mse: 0.0075\n",
      "Epoch 46/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0072 - mae: 0.0636 - mse: 0.0072 - val_loss: 0.0069 - val_mae: 0.0612 - val_mse: 0.0069\n",
      "Epoch 47/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0069 - mae: 0.0620 - mse: 0.0069 - val_loss: 0.0068 - val_mae: 0.0610 - val_mse: 0.0068\n",
      "Epoch 48/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0071 - mae: 0.0633 - mse: 0.0071 - val_loss: 0.0084 - val_mae: 0.0730 - val_mse: 0.0084\n",
      "Epoch 49/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0630 - mse: 0.0070 - val_loss: 0.0071 - val_mae: 0.0643 - val_mse: 0.0071\n",
      "Epoch 50/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0072 - mae: 0.0643 - mse: 0.0072 - val_loss: 0.0068 - val_mae: 0.0598 - val_mse: 0.0068\n",
      "Epoch 51/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0609 - mse: 0.0067 - val_loss: 0.0065 - val_mae: 0.0595 - val_mse: 0.0065\n",
      "Epoch 52/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0616 - mse: 0.0067 - val_loss: 0.0069 - val_mae: 0.0637 - val_mse: 0.0069\n",
      "Epoch 53/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0616 - mse: 0.0067 - val_loss: 0.0080 - val_mae: 0.0666 - val_mse: 0.0080\n",
      "Epoch 54/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0607 - mse: 0.0066 - val_loss: 0.0066 - val_mae: 0.0618 - val_mse: 0.0066\n",
      "Epoch 55/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0619 - mse: 0.0067 - val_loss: 0.0116 - val_mae: 0.0903 - val_mse: 0.0116\n",
      "Epoch 56/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0637 - mse: 0.0070 - val_loss: 0.0065 - val_mae: 0.0598 - val_mse: 0.0065\n",
      "Epoch 57/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0601 - mse: 0.0065 - val_loss: 0.0064 - val_mae: 0.0600 - val_mse: 0.0064\n",
      "Epoch 58/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0614 - mse: 0.0067 - val_loss: 0.0064 - val_mae: 0.0586 - val_mse: 0.0064\n",
      "Epoch 59/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0605 - mse: 0.0065 - val_loss: 0.0066 - val_mae: 0.0615 - val_mse: 0.0066\n",
      "Epoch 60/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0603 - mse: 0.0065 - val_loss: 0.0062 - val_mae: 0.0579 - val_mse: 0.0062\n",
      "Epoch 61/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0609 - mse: 0.0065 - val_loss: 0.0072 - val_mae: 0.0636 - val_mse: 0.0072\n",
      "Epoch 62/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0603 - mse: 0.0064 - val_loss: 0.0067 - val_mae: 0.0626 - val_mse: 0.0067\n",
      "Epoch 63/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0612 - mse: 0.0066 - val_loss: 0.0072 - val_mae: 0.0636 - val_mse: 0.0072\n",
      "Epoch 64/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0608 - mse: 0.0065 - val_loss: 0.0061 - val_mae: 0.0581 - val_mse: 0.0061\n",
      "Epoch 65/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0597 - mse: 0.0064 - val_loss: 0.0062 - val_mae: 0.0574 - val_mse: 0.0062\n",
      "Epoch 66/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0069 - mae: 0.0626 - mse: 0.0069 - val_loss: 0.0070 - val_mae: 0.0626 - val_mse: 0.0070\n",
      "Epoch 67/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0603 - mse: 0.0065 - val_loss: 0.0061 - val_mae: 0.0569 - val_mse: 0.0061\n",
      "Epoch 68/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0589 - mse: 0.0062 - val_loss: 0.0113 - val_mae: 0.0896 - val_mse: 0.0113\n",
      "Epoch 69/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0589 - mse: 0.0062 - val_loss: 0.0060 - val_mae: 0.0565 - val_mse: 0.0060\n",
      "Epoch 70/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0596 - mse: 0.0063 - val_loss: 0.0084 - val_mae: 0.0751 - val_mse: 0.0084\n",
      "Epoch 71/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0627 - mse: 0.0068 - val_loss: 0.0074 - val_mae: 0.0685 - val_mse: 0.0074\n",
      "Epoch 72/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0594 - mse: 0.0063 - val_loss: 0.0061 - val_mae: 0.0581 - val_mse: 0.0061\n",
      "Epoch 73/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0593 - mse: 0.0063 - val_loss: 0.0065 - val_mae: 0.0606 - val_mse: 0.0065\n",
      "Epoch 74/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0597 - mse: 0.0063 - val_loss: 0.0082 - val_mae: 0.0731 - val_mse: 0.0082\n",
      "Epoch 75/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0588 - mse: 0.0062 - val_loss: 0.0066 - val_mae: 0.0606 - val_mse: 0.0066\n",
      "Epoch 76/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0592 - mse: 0.0063 - val_loss: 0.0060 - val_mae: 0.0565 - val_mse: 0.0060\n",
      "Epoch 77/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0601 - mse: 0.0064 - val_loss: 0.0069 - val_mae: 0.0623 - val_mse: 0.0069\n",
      "Epoch 78/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0590 - mse: 0.0062 - val_loss: 0.0068 - val_mae: 0.0646 - val_mse: 0.0068\n",
      "Epoch 79/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0598 - mse: 0.0063 - val_loss: 0.0069 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 80/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0610 - mse: 0.0065 - val_loss: 0.0066 - val_mae: 0.0629 - val_mse: 0.0066\n",
      "Epoch 81/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0066 - mae: 0.0615 - mse: 0.0066 - val_loss: 0.0063 - val_mae: 0.0596 - val_mse: 0.0063\n",
      "Epoch 82/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0596 - mse: 0.0063 - val_loss: 0.0074 - val_mae: 0.0687 - val_mse: 0.0074\n",
      "Epoch 83/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0591 - mse: 0.0062 - val_loss: 0.0067 - val_mae: 0.0634 - val_mse: 0.0067\n",
      "Epoch 84/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0064 - mae: 0.0601 - mse: 0.0064 - val_loss: 0.0060 - val_mae: 0.0574 - val_mse: 0.0060\n",
      "Epoch 85/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0592 - mse: 0.0063 - val_loss: 0.0063 - val_mae: 0.0582 - val_mse: 0.0063\n",
      "Epoch 86/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0593 - mse: 0.0063 - val_loss: 0.0074 - val_mae: 0.0688 - val_mse: 0.0074\n",
      "Epoch 87/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0593 - mse: 0.0063 - val_loss: 0.0060 - val_mae: 0.0570 - val_mse: 0.0060\n",
      "Epoch 88/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0594 - mse: 0.0063 - val_loss: 0.0060 - val_mae: 0.0572 - val_mse: 0.0060\n",
      "Epoch 89/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0589 - mse: 0.0062 - val_loss: 0.0073 - val_mae: 0.0684 - val_mse: 0.0073\n",
      "Epoch 90/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0580 - mse: 0.0061 - val_loss: 0.0058 - val_mae: 0.0553 - val_mse: 0.0058\n",
      "Epoch 91/200\n",
      "324/324 [==============================] - 0s 987us/step - loss: 0.0062 - mae: 0.0589 - mse: 0.0062 - val_loss: 0.0063 - val_mae: 0.0608 - val_mse: 0.0063\n",
      "Epoch 92/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0578 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0555 - val_mse: 0.0059\n",
      "Epoch 93/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0592 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0558 - val_mse: 0.0059\n",
      "Epoch 94/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0591 - mse: 0.0062 - val_loss: 0.0062 - val_mae: 0.0572 - val_mse: 0.0062\n",
      "Epoch 95/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0065 - mae: 0.0608 - mse: 0.0065 - val_loss: 0.0071 - val_mae: 0.0658 - val_mse: 0.0071\n",
      "Epoch 96/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0060 - mae: 0.0573 - mse: 0.0060 - val_loss: 0.0084 - val_mae: 0.0725 - val_mse: 0.0084\n",
      "Epoch 97/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0592 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0560 - val_mse: 0.0059\n",
      "Epoch 98/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0584 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0555 - val_mse: 0.0059\n",
      "Epoch 99/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0618 - mse: 0.0067 - val_loss: 0.0059 - val_mae: 0.0573 - val_mse: 0.0059\n",
      "Epoch 100/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0586 - mse: 0.0062 - val_loss: 0.0077 - val_mae: 0.0706 - val_mse: 0.0077\n",
      "Epoch 101/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0593 - mse: 0.0063 - val_loss: 0.0062 - val_mae: 0.0581 - val_mse: 0.0062\n",
      "Epoch 102/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0594 - mse: 0.0063 - val_loss: 0.0060 - val_mae: 0.0572 - val_mse: 0.0060\n",
      "Epoch 103/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0061 - mae: 0.0585 - mse: 0.0061 - val_loss: 0.0064 - val_mae: 0.0617 - val_mse: 0.0064\n",
      "Epoch 104/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0062 - mae: 0.0588 - mse: 0.0062 - val_loss: 0.0058 - val_mae: 0.0554 - val_mse: 0.0058\n",
      "Epoch 105/200\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0060 - mae: 0.0576 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0565 - val_mse: 0.0059\n",
      "Epoch 105: early stopping\n",
      "253/253 [==============================] - 0s 739us/step\n",
      "64/64 [==============================] - 0s 654us/step\n",
      "\n",
      "xCO2(predicted) - xCO2(actual)\n",
      "Train. mean:  0.009665606580720012    std:  0.07581617098270979    MAE:  0.05565022755285653     R2:  0.9495506352290429\n",
      "Test. mean:  0.012248192520513441    std:  0.07615194024032104    MAE:  0.056533198554956886     R2:  0.9468420890823067\n",
      "\n",
      "Duration :  00:02:33 401ms\n",
      "\u001b[1maverage MAE of the training set:\u001b[0m   0.09 +/- 0.06\n",
      "\u001b[1maverage MAE of the validation set:\u001b[0m 0.09 +/- 0.06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# optimization of the ANN\n",
    "# library used: keras and scikit learn for the KFold cross-validator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "VERBOSE = 1\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 25\n",
    "N_SPLIT = 5\n",
    "\n",
    "vID.chrono_start()\n",
    "\n",
    "# variables created to save at each iteration of the KFold process: the man error, the standard deviation, MAE, R2\n",
    "meantT=list()\n",
    "stdtT=list()\n",
    "MAEtT=list()\n",
    "R2tT=list()\n",
    "meanvT=list()\n",
    "stdvT=list()\n",
    "MAEvT=list()\n",
    "R2vT=list()\n",
    "\n",
    "kfold = KFold(n_splits=N_SPLIT,shuffle=True,random_state=42) # k-fold is here!\n",
    "#print(list(kfold.split(x_train,y_train)))\n",
    "\n",
    "j = 0 # Variable for keeping count of split we are executing\n",
    "# The KFold cv provides train/test indices to split data in train/test sets\n",
    "for train_idx, val_idx in list(kfold.split(xdata,ydata)):\n",
    "\n",
    "    x_train_cv = xdata.iloc[train_idx]\n",
    "    x_valid_cv = xdata.iloc[val_idx]\n",
    "    y_train_cv = ydata.iloc[train_idx]\n",
    "    y_valid_cv = ydata.iloc[val_idx]\n",
    "#    display(x_train_cv,x_valid_cv)\n",
    "# This part has been commented with respect to the original script\n",
    "    # scaler = preprocessing.StandardScaler()\n",
    "    # scaler.fit(x_train_cv.values)\n",
    "    # xt_scaled = scaler.transform(x_train_cv.values) #returns a numpy array\n",
    "    # xv_scaled = scaler.transform(x_valid_cv.values) #returns a numpy array\n",
    "    # x_train_cv = pd.DataFrame(xt_scaled, index=x_train_cv.index, columns=x_train_cv.columns)\n",
    "    # x_valid_cv = pd.DataFrame(xv_scaled, index=x_valid_cv.index, columns=x_valid_cv.columns)\n",
    "    # del xt_scaled, xv_scaled\n",
    "##############\n",
    "#    display(x_train_cv.describe().style.format(\"{0:.2f}\").set_caption(\"Training set after normalization (with scikit-learn):\"))\n",
    "#    display(x_valid_cv.describe().style.format(\"{0:.2f}\").set_caption(\"Validation set after normalization (with scikit-learn):\"))\n",
    "    print(f\"{color.BOLD}{color.RED}Fold {j}{color.OFF}\")\n",
    "    j+=1\n",
    "    ANNmodel=defANN( (53,), acthL )\n",
    "    ANNhistory = ANNmodel.fit(x_train_cv,\n",
    "                        y_train_cv,\n",
    "                        epochs          = EPOCHS,\n",
    "                        batch_size      = BATCH_SIZE,\n",
    "                        verbose         = VERBOSE,\n",
    "                        validation_data = (x_valid_cv, y_valid_cv),\n",
    "                        callbacks=[es])\n",
    "    ytrain_hat=ANNmodel.predict(x_train_cv)\n",
    "    yvalid_hat=ANNmodel.predict(x_valid_cv)\n",
    "    diffyt = ytrain_hat.ravel() - y_train_cv.ravel()\n",
    "    diffyv = yvalid_hat.ravel() - y_valid_cv.ravel()\n",
    "\n",
    "    print()\n",
    "    print(\"xCO2(predicted) - xCO2(actual)\")\n",
    "    print(\n",
    "          \"Train.\",\"mean: \", np.mean(diffyt),\n",
    "          \"   std: \", np.std(diffyt),\n",
    "          \"   MAE: \", np.average(abs(diffyt)),\n",
    "          \"    R2: \", np.corrcoef(y_train_cv.ravel(),ytrain_hat.ravel())[0,1]\n",
    "         )\n",
    "    print(\n",
    "          \"Test.\",\"mean: \", np.mean(diffyv),\n",
    "          \"   std: \", np.std(diffyv),\n",
    "          \"   MAE: \", np.average(abs(diffyv)),\n",
    "          \"    R2: \", np.corrcoef(y_valid_cv.ravel(),yvalid_hat.ravel())[0,1]\n",
    "         )\n",
    "    meantT.append(np.mean(diffyt))\n",
    "    meanvT.append(np.mean(diffyv))\n",
    "    stdtT.append(np.std(diffyt))\n",
    "    stdvT.append(np.std(diffyv))\n",
    "    MAEtT.append(np.average(abs(diffyt)))\n",
    "    MAEvT.append(np.average(abs(diffyv)))\n",
    "    R2tT.append(np.corrcoef(y_train_cv.ravel(),ytrain_hat.ravel())[0,1])\n",
    "    R2vT.append(np.corrcoef(y_valid_cv.ravel(),yvalid_hat.ravel())[0,1])\n",
    "    \n",
    "vID.chrono_show()\n",
    "\n",
    "#######################################################################################\n",
    "# accuracy of the ANN?\n",
    "# library used: numpy\n",
    "print(f\"{color.BOLD}average MAE of the training set:{color.OFF}   {np.mean(MAEtT):.2f} +/- {np.std(MAEtT):.2f}\")\n",
    "print(f\"{color.BOLD}average MAE of the validation set:{color.OFF} {np.mean(MAEvT):.2f} +/- {np.std(MAEvT):.2f}\")\n",
    "\n",
    "figCV, axCV = plt.subplots(1, 1)\n",
    "figCV.set_size_inches(12,5)\n",
    "axCV.errorbar(x=np.arange(len(meantT)), y=meantT, yerr=MAEtT, label='training sets', fmt='o-', capsize=10)\n",
    "axCV.errorbar(x=np.arange(len(meanvT))+0.1, y=meanvT, yerr=MAEvT, label='validation sets', fmt='o-', capsize=10)\n",
    "axCV.legend(loc='lower left', shadow=True, fontsize='14')\n",
    "axCV.set_xlabel('cross-validation k-values ',fontdict={'fontsize':16})\n",
    "axCV.set_ylabel('$\\hat{y}-y_{\\mathrm{actual}}$',fontdict={'fontsize':16})\n",
    "axCV.tick_params(labelsize = 14)\n",
    "plt.savefig('../DS4B-CO2-images/KFold-cv-AppliedToSong_etal.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d639724-2e98-43dd-b6e5-7f0767cfb27d",
   "metadata": {},
   "source": [
    "<div class=\"warn\">\n",
    "You have probably found results similar to those reported in the following error plot:\n",
    "<p style=\"text-align: center\"><img width=\"650px\" src=\"../DS4B-CO2-images/KFold-cv-AppliedToSong_etalK-saved.png\" style=\"margin-left:auto; margin-right:auto\" id=\"img_ResultsSong\"></p>\n",
    "    <b>This error plot shows a bad performance of the original ML algorithm of Song <i>et al</i>. (<i>i.e.</i> without standardization of the data), with a strong variation of error bars.</b>\n",
    "    \n",
    "Either the authors did actually apply a standardization preprocessing and they forgot to mention it in the article, or they ran several optimization algorithms of the ANN until they found a seemingly performant one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1998a632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**End at:** Monday 31 October 2022, 21:05:33  \n",
       "**Duration:** 00:05:06 796ms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"../config/svg/logoEnd.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vID.end(cwd0)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
