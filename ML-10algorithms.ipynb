{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98662e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: bold;\n",
       "}\n",
       "body, intro, introE, introT, rq, rqE, rqT, ex, exE, app, appE, sol, todo, figure  {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: 400;\n",
       "  font-size: 12px;\n",
       "}\n",
       "h1 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 30px ;\n",
       "  color: white;\n",
       "  background: #b11d01;\n",
       "  text-align: center;\n",
       "}\n",
       "h2 {\n",
       "  border: 3px solid #333;\n",
       "  padding: 18px ;\n",
       "  color: #b11d01;\n",
       "  background: #ffffff;\n",
       "  text-align: center;\n",
       "}\n",
       "h3 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 12px ;\n",
       "  color: #000000;\n",
       "  background: #c1c1c1;\n",
       "  text-align: left;\n",
       "}\n",
       "h4 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #d9fffc;\n",
       "  text-align: left;\n",
       "}\n",
       "h5 {\n",
       "  border: 1px solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #ffffff;\n",
       "  text-align: left;\n",
       "}\n",
       ".introT::before {    \n",
       "    content: attr(title);\n",
       "    background-color: #cecece;\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".introT {    \n",
       "    background-color: #cecece80;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".intro {    \n",
       "    background-color: #cecece80;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".introE {    \n",
       "    background-color: #cecece80;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "    color : #117996;\n",
       "}\n",
       ".rq::before {    \n",
       "    background-color: #fcd3d3;\n",
       "    color: #ff0000;\n",
       "    content:\"Remarque\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".rq {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".rqE::before {    \n",
       "    background-color: #fcd3d3;\n",
       "    color: #ff0000;\n",
       "    content:\"Pay attention\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".rqE {    \n",
       "    background-color: #fcd3d380;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".rqT::before {    \n",
       "    background-color: #fcd3d3;\n",
       "    color: #ff0000;\n",
       "    content: attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".rqT {    \n",
       "    background-color: #fcd3d380;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".exold {    \n",
       "    background-color: #b2dbea80;\n",
       "    border-color: #0055ff;\n",
       "    border-left: 10px solid #0055ff;\n",
       "    padding: 0.5em;\n",
       "}\n",
       ".ex {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".ex::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Exercice. \" attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".exE {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "    color : #117996;\n",
       "}\n",
       ".exE::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Exercise. \" attr(title);\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "    color : #117996;\n",
       "}\n",
       ".app {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".app::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Application\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".appE {    \n",
       "    background-color: #b2dbea80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    color : #117996;\n",
       "    position:relative;\n",
       "}\n",
       ".appE::before {\n",
       "    background-color: #b2dbea;\n",
       "    content:\"Application\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    color : #117996;\n",
       "    display: block;\n",
       "}\n",
       ".sol {    \n",
       "    background-color: #bbeab880;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".sol::before {\n",
       "    background-color: #bbeab8;\n",
       "    content:\"Answer\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       ".com {    \n",
       "    background-color: #ffff7f80;\n",
       "    padding: 0.5em;\n",
       "    padding-top: 0em;\n",
       "    position:relative;\n",
       "}\n",
       ".com::before {\n",
       "    background-color: #ffff7f;\n",
       "    content:\"Comment.\";\n",
       "    margin-left:-0.5em;\n",
       "    margin-right:-0.5em;\n",
       "    padding-left:0.5em;\n",
       "    padding-right:0.5em;\n",
       "    font-weight: 600;\n",
       "    display: block;\n",
       "}\n",
       "div.todo:before {\n",
       "    content:url(data:image/png;base64,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);\n",
       "    float:left;\n",
       "    margin-left:20px;\n",
       "    margin-right:20px;\n",
       "    margin-top:20px;\n",
       "    margin-bottom:20px;\n",
       "}\n",
       "div.todo{\n",
       "    font-size: 1.1em;\n",
       "    margin-top:40px;\n",
       "    background-color: #b2dbea80;\n",
       "}\n",
       "div.todo ul{\n",
       "    margin: 0.2em;\n",
       "}\n",
       "div.todo li{\n",
       "    margin-left:60px;\n",
       "    margin-top:0;\n",
       "    margin-bottom:0;\n",
       "}\n",
       "\n",
       "figure {\n",
       "    border: 0px;\n",
       "    text-align: center;\n",
       "    margin: 5px; /* adjust as needed */\n",
       "    display: block;\n",
       "    margin: auto;\n",
       "}\n",
       "figure img {\n",
       "    vertical-align: top;\n",
       "    text-align: center;\n",
       "    display: block;\n",
       "    margin: auto;\n",
       "}\n",
       "figure figcaption {\n",
       "    border: 0px;\n",
       "    text-align: center;\n",
       "    font-size: 11px;\n",
       "    margin: auto;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Start at:** Monday 17 June 2024, 15:08:27  \n",
       "**Hostname:** localhost.localdomain (Linux)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"./config/svg/pyPhysChemBanner.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cwd0 = './config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID_Eng as vID\n",
    "from visualID_Eng import color, fg, bg, hl\n",
    "vID.init(cwd0)\n",
    "import tools4pyPhysChem as t4pPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff349db3-abff-4dc8-a639-e953a5097961",
   "metadata": {},
   "source": [
    "# Top 10 Machine Learning Algorithms For Beginners: Supervised, and More\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe15cb0-bf0b-41d3-a91f-217bd008af5c",
   "metadata": {},
   "source": [
    "## Why is the random seed initialized to 42 in most datascience and ML applications?\n",
    "\n",
    "<div class=\"rqE\">\n",
    "\n",
    "It comes from Douglas Adams’s popular 1979 science-fiction novel *The Hitchhiker’s Guide to the Galaxy*. Toward the end of the book, the supercomputer Deep Thought reveals that the answer to the “Great Question” of “Life, the Universe and Everything” is “**forty-two**”. It took 7.5 million years to Deep Thought to calculate the answer to the ultimate question...\n",
    "\n",
    "The author’s choice of the number 42 has become a reference in nerd culture. And it has its own [wikipedia entry](https://en.wikipedia.org/wiki/42_(number))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525de4c-be9a-433b-bb65-d1a231c04c0d",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "<div class=\"introT\" title=\"The database\">\n",
    "\n",
    "Ten baseline variables, age, sex, body mass index (bmi), average blood pressure (bp), and six blood serum measurements (s1 to s6) were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline, see [https://scikit-learn.org/](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)\n",
    "\n",
    "Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of n_samples (i.e. the sum of squares of each column totals 1)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513b8422-e3e6-4812-acf2-547b5f179ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 42.79409467959994\n",
      "MSE is: 2900.193628493482\n",
      "R2 score is: 0.4526027629719195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "# Convert the dataset to a DataFrame\n",
    "diabetes_df = pd.DataFrame(data=diabetes.data,\n",
    "                           columns=diabetes.feature_names)\n",
    "\n",
    "# Add target variable to the DataFrame\n",
    "diabetes_df['target'] = diabetes.target\n",
    "display(diabetes_df)\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MAE is:\", mae)\n",
    "print(\"MSE is:\", mse)\n",
    "print(\"R2 score is:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185fc4c-1bbf-40e5-bb59-ed21d6073733",
   "metadata": {},
   "source": [
    "<div class=\"rq\">\n",
    "\n",
    "These results indicate that such Linear Regression model explains about 45% of the variance in the diabetes dataset. The MAE tells us that predictions are about 43 units away from the true values... which is obviously bad. **Such linear model is not adapted at all**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca82231-f471-4cee-a211-75c0620179d9",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "<div class=\"introT\" title=\"The model\">\n",
    "\n",
    "Logistic Regression is used for classification problems. It predicts the probability that a given data point belongs to a certain class, like yes/no or 0/1. It uses a logistic function to output a value between 0 and 1. This value is then mapped to a specific class based on a threshold (usually 0.5)\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"introT\" title=\"The database\">\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image, see description at [https://scikit-learn.org/](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) or on [UC Irvine ML repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caf2eb99-c8b0-4493-918f-d6ff5a280c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Precision: 0.95\n",
      "Recall: 0.99\n",
      "F1 score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "# Convert the dataset to a DataFrame\n",
    "breast_cancer_df = pd.DataFrame(data=breast_cancer.data,\n",
    "                           columns=breast_cancer.feature_names)\n",
    "\n",
    "# Add target variable to the DataFrame\n",
    "breast_cancer_df['target'] = breast_cancer.target\n",
    "display(breast_cancer_df)\n",
    "\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6fc79-0fab-4a44-a831-1dd6f816c1f4",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "About the metrics:\n",
    "- the recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives\n",
    "- the F1 score is the harmonic mean of the precision and recall. It thus symmetrically represents both precision and recall in one metric\n",
    "\n",
    "The high recall indicates that **the model is particularly good at identifying malignant cases**, which is crucial in medical diagnostics.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bc45f-dd53-46ed-95c9-19ff8cf0e739",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "\n",
    "<div class=\"introT\" title=\"The model\">\n",
    "\n",
    "This is a supervised learning algorithm that is used for **classifying problems**. It works well in classifying both categorical and continuous dependent variables. This algorithm divides the population into two or more homogeneous sets based on the most significant attributes/ independent variables.\n",
    "\n",
    "Decision Trees are like flowcharts, splitting the data based on certain conditions or features. They are applied to regression as well as classification.\n",
    "\n",
    "The way it operates is by using feature values to split the dataset into more manageable subgroups. Every internal node symbolizes an attribute test, every branch denotes the test’s result, and every leaf node represents a class label, *i.e.* the decision\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"introT\" title=\"The database\">\n",
    "\n",
    "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine, each type being related to a specific grape variety; see description at [https://scikit-learn.org/](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) or on [UC Irvine ML repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f1ea6c1-8466-43a0-a3b4-e0e0933446d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Precision: 0.95\n",
      "Recall: 0.93\n",
      "F1 score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "wine_df = pd.DataFrame(data=wine.data,\n",
    "                           columns=wine.feature_names)\n",
    "\n",
    "# Add target variable to the DataFrame\n",
    "wine_df['target'] = wine.target\n",
    "display(wine_df)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c37ea-69d9-4b71-9b9f-87146bc4e41e",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "These results indicate that **the Decision Tree model performs very well on this dataset**, given its ability to accurately predict a particular class of wine.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702749e-5191-48e1-9c9a-fa639ced6f33",
   "metadata": {},
   "source": [
    "## Naive bayes\n",
    "\n",
    "### Introduction\n",
    "\n",
    "<div class=\"introT\" title=\"The model\">\n",
    "\n",
    "A Naive Bayes classifier is based on Bayes' Theorem and the assumption of feature independence, in other words it assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n",
    "Even if these features are related to each other, a Naive Bayes classifier would consider all of these properties independently when calculating the probability of a particular outcome.\n",
    "\n",
    "A Naive Bayesian model is easy to build and useful for massive datasets. It's simple and is known to outperform even highly sophisticated classification methods.\n",
    "\n",
    "These classifiers are a family of simple “probabilistic classifiers” that use the Bayes theorem and strong (naive) independence assumptions between the features. It’s particularly used in text classification problems such as spam detection, sentiment analysis, and document categorization\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"introT\" title=\"The Bayes theorem\">\n",
    "\n",
    "Here's a more detailed explanation:\n",
    "\n",
    "#### Key Concepts:\n",
    "\n",
    "1. **Bayes' Theorem:**\n",
    "\n",
    "Bayes' Theorem describes the probability of an event A, based on prior knowledge of conditions, B, that might be related to the event. It is expressed as:\n",
    "$$\\mathcal{P}(\\mathrm{A|B})=\\frac{\\mathcal{P}(\\mathrm{B|A})\\cdot\\mathcal{P}(\\mathrm{A})}{\\mathcal{P}(\\mathrm{B})}$$\n",
    "\n",
    "where:\n",
    "- $\\mathcal{P}(\\mathrm{A|B})$ is the posterior probability of class A given predictor B\n",
    "- $\\mathcal{P}(\\mathrm{B|A})$ is the likelihood of predictor B given class A\n",
    "- $\\mathcal{P}(\\mathrm{A})$ is the prior probability of class A\n",
    "- $\\mathcal{P}(\\mathrm{B})$ is the prior probability of predictor B\n",
    "\n",
    "2. **Naive Assumption of Independence:**\n",
    "   The \"naive\" part of Naive Bayes assumes that the features are independent of each other given the class. This simplification makes the calculation of the joint probability of the features easier and computationally efficient.\n",
    "\n",
    "#### Types of Naive Bayes Classifiers:\n",
    "\n",
    "1. **Gaussian Naive Bayes:**\n",
    "   Assumes that the features follow a normal distribution. This is useful for continuous data.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   Used for discrete data and often applied in text classification with word counts or frequencies.\n",
    "\n",
    "3. **Bernoulli Naive Bayes:**\n",
    "   Also used for discrete data, but specifically for binary/boolean features (e.g., presence or absence of a word in text classification).\n",
    "\n",
    "#### How Naive Bayes Works:\n",
    "\n",
    "1. **Training Phase:**\n",
    "   - Calculate the prior probability for each class.\n",
    "   - Calculate the likelihood of each feature given each class.\n",
    "   - Store these probabilities for use during the prediction phase.\n",
    "\n",
    "2. **Prediction Phase:**\n",
    "   - For a new instance, calculate the posterior probability for each class using Bayes' Theorem.\n",
    "   - Choose the class with the highest posterior probability as the predicted class.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Let's say we have a simple dataset of emails labeled as \"spam\" or \"not spam\" with features representing the presence of specific words, namely Free, Win , Click.\n",
    "\n",
    "##### Training Data\n",
    "\n",
    "| Email   | Free | Win | Click | Label     |\n",
    "|---------|--------|-------|---------|-----------|\n",
    "| Email 1 | Yes    | Yes   | Yes     | Spam      |\n",
    "| Email 2 | No     | Yes   | No      | Not Spam  |\n",
    "| Email 3 | Yes    | No    | Yes     | Spam      |\n",
    "| Email 4 | No     | No    | No      | Not Spam  |\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. **Calculate Prior Probabilities:**\n",
    "   \n",
    "- $\\mathcal{P}(\\text{Spam}) = \\frac{2}{4} = 0.5$\n",
    "- $\\mathcal{P}(\\text{Not Spam}) = \\frac{2}{4} = 0.5$\n",
    "\n",
    "2. **Calculate Likelihoods:**\n",
    "- $\\mathcal{P}(\\text{Free}|\\text{Spam}) = \\frac{2}{2} = 1$\n",
    "- $\\mathcal{P}(\\text{Win}|\\text{Spam}) = \\frac{1}{2} = 0.5$\n",
    "- $\\mathcal{P}(\\text{Click}|\\text{Spam}) = \\frac{2}{2} = 1$\n",
    "- $\\mathcal{P}(\\text{Free}|\\text{Not Spam}) = \\frac{0}{2} = 0$\n",
    "- $\\mathcal{P}(\\text{Win}|\\text{Not Spam}) = \\frac{1}{2} = 0.5$\n",
    "- $\\mathcal{P}(\\text{Click}|\\text{Not Spam}) = \\frac{0}{2} = 0$\n",
    "\n",
    "3. **Predict a New Email:**\n",
    "\n",
    "For a new email with features \"Free: Yes\", \"Win: Yes\", \"Click: Yes\":\n",
    "\n",
    "$$\\mathcal{P}(\\text{Spam|Email}) = \\frac{\\mathcal{P}(\\text{Email|Spam}) \\cdot \\mathcal{P}(\\text{Spam})}{\\mathcal{P}(\\text{Email})} \\approx \\mathcal{P}(\\text{Free|Spam}) \\cdot \\mathcal{P}(\\text{Win|Spam}) \\cdot \\mathcal{P}(\\text{Click|Spam}) \\cdot \\mathcal{P}(\\text{Spam}) \\approx 1 \\cdot 0.5 \\cdot 1 \\cdot 0.5 = 0.25$$\n",
    "\n",
    "Similarly, calculate for Not Spam:\n",
    "\n",
    "$$\\mathcal{P}(\\text{Not Spam|Email}) \\approx \\mathcal{P}(\\text{Free|Not Spam}) \\cdot \\mathcal{P}(\\text{Win|Not Spam}) \\cdot \\mathcal{P}(\\text{Click|Not Spam}) \\cdot \\mathcal{P}(\\text{Not Spam}) \\approx 0 \\cdot 0.5 \\cdot 0 \\cdot 0.5 = 0$$\n",
    "\n",
    "Since $\\mathcal{P}(\\text{Spam|Email}) > \\mathcal{P}(\\text{Not Spam|Email})$, we classify the new email as Spam.\n",
    "\n",
    "#### Cons and pros\n",
    "\n",
    "##### Advantages:\n",
    "\n",
    "- Simple to understand and implement.\n",
    "- Requires less training data.\n",
    "- Handles both continuous and discrete data.\n",
    "- Highly scalable with the number of predictors/features.\n",
    "\n",
    "##### Disadvantages:\n",
    "\n",
    "- The assumption of independent predictors is rarely true in real-world applications.\n",
    "- Can perform poorly if the feature independence assumption is violated.\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"introT\" title=\"The database\">\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55202f55-4ee8-4d42-9ed9-120ee965327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Precision: 0.86\n",
      "Recall: 0.85\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d061ef-556e-495d-9fcf-c1ef41ccf2bd",
   "metadata": {},
   "source": [
    "<div class=\"rqE\">\n",
    "\n",
    "The Naive Bayes model has a **good performance** on this dataset, with fairly balanced precision and recall. It is quite effective in classifying handwritten digits, though there’s **room for improvement**, especially in terms of accuracy and F1 score.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944948fd-7b9c-4bcf-a768-f01f0423f985",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab9435a-1af2-465e-b7a8-dcd633f84acd",
   "metadata": {},
   "source": [
    "# Bibliography and useful links\n",
    "\n",
    "[Top 10 Machine Learning Algorithms For Beginners: Supervised, and More, by Simon Tavasoli](https://www.simplilearn.com/10-algorithms-machine-learning-engineers-need-to-know-article)\n",
    "\n",
    "[Top 10 Machine Learning Algorithms for Beginner Data Scientists](https://medium.com/@nathanrosidi/top-10-machine-learning-algorithms-for-beginner-data-scientists-aae78826712f)\n",
    "\n",
    "[Wikipedia page on the perceptron model](https://en.wikipedia.org/wiki/Perceptron)\n",
    "\n",
    "[Hands-on machine learning with scikit-learn, keras and tensorflow (3rd edition, **2022**), Aurélien Géron, O'Reilly editions](https://github.com/ageron/handson-ml3)\n",
    "\n",
    "[TensorFlow 2 Tutorial: Get Started in Deep Learning with tf.keras](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/)\n",
    "\n",
    "Some images were generated with [DALL·E](https://openai.com/dall-e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dea101f-ce6f-47ee-819c-a2fb77f6f708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**End at:** Wednesday 27 March 2024, 12:26:09  \n",
       "**Duration:** 00:06:30 896ms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"./config/svg/logoEnd.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vID.end(cwd0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af59d5-ee74-417c-87d0-2cc5096025c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
